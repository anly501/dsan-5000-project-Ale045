[
  {
    "objectID": "naive_bayes.html",
    "href": "naive_bayes.html",
    "title": "Naive Bayes",
    "section": "",
    "text": "Naive Bayes is a classification algorithm that is suitable for binary and multiclass classification. It is based on the Bayes theorem and assumes that the features are independent of each other which is why it is called naive. Though the assumption does not hold true for most statistical data, the algorithm still achive good performace in many cases."
  },
  {
    "objectID": "naive_bayes.html#introduction-to-naive-bayes",
    "href": "naive_bayes.html#introduction-to-naive-bayes",
    "title": "Naive Bayes",
    "section": "",
    "text": "Naive Bayes is a classification algorithm that is suitable for binary and multiclass classification. It is based on the Bayes theorem and assumes that the features are independent of each other which is why it is called naive. Though the assumption does not hold true for most statistical data, the algorithm still achive good performace in many cases."
  },
  {
    "objectID": "naive_bayes.html#bayes-theorem",
    "href": "naive_bayes.html#bayes-theorem",
    "title": "Naive Bayes",
    "section": "Bayes Theorem",
    "text": "Bayes Theorem\nBayes theorem is a probabability theory which update the prior belife by incorporating new evidence. The formula is as follows:\n\\[P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\\]\nwhere \\(P(A|B)\\) is the posterior probability, \\(P(B|A)\\) is the likelihood, \\(P(A)\\) is the prior probability and \\(P(B)\\) is the evidence.\nIn a Naive Bayes classifier, each time we use this formula to calculate the posterior probability of each class and the class with the highest probability is the predicted class."
  },
  {
    "objectID": "naive_bayes.html#aim",
    "href": "naive_bayes.html#aim",
    "title": "Naive Bayes",
    "section": "Aim",
    "text": "Aim\nIn this project, I will propse two Naive Bayes classifer which one of them will be using the music’s acoustic features to predcit the year range of the song and the other using the lyric of the song to predict the valence stage."
  },
  {
    "objectID": "naive_bayes.html#different-types-of-naive-bayes-classifiers",
    "href": "naive_bayes.html#different-types-of-naive-bayes-classifiers",
    "title": "Naive Bayes",
    "section": "Different types of Naive Bayes Classifiers",
    "text": "Different types of Naive Bayes Classifiers\n\nGaussian Naive Bayes: It is used in classification and assumes that the features follow a normal distribution.This is normally used when dealing with contiouns data.\nMultinomial Naive Bayes: It is used in classification and assumes that the features follow a multinomial distribution. This is normally used when dealing with discrete data.\nBernoulli Naive Bayes: It is used in classification and assumes that the features follow a Bernoulli distribution. This is normally used when dealing with binary data."
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "An Analysis of the Trend in Today’s Music Industry",
    "section": "",
    "text": "Music, arguably invented earlier than language, has been an important part of human civilization. During the years music has been constantly evolving and could be serve as a reflection on the society of its time. The pace of the evolve though, is noticeable accelerated in recent years. With the new technology and the rise of Gen Z as main consumer, nearly every aspect of the industry has changed significantly. New genres such as sped-ups are emerging in a speedy way and streaming service has completely changed the way consumer access to music and hence their consuming behaviors. More powerful AI tools help independent artist to produce quality works, while crossover between music and video and games become a new force due to platform like TikTok. To understand the trend in contemporary music offers not only a great commercial value but also provide us an insight into modern society and this new generation. In this project, we will employ a data driven method to depict the revolution in music industry and try to predict its future."
  },
  {
    "objectID": "introduction.html#project-introduction",
    "href": "introduction.html#project-introduction",
    "title": "An Analysis of the Trend in Today’s Music Industry",
    "section": "",
    "text": "Music, arguably invented earlier than language, has been an important part of human civilization. During the years music has been constantly evolving and could be serve as a reflection on the society of its time. The pace of the evolve though, is noticeable accelerated in recent years. With the new technology and the rise of Gen Z as main consumer, nearly every aspect of the industry has changed significantly. New genres such as sped-ups are emerging in a speedy way and streaming service has completely changed the way consumer access to music and hence their consuming behaviors. More powerful AI tools help independent artist to produce quality works, while crossover between music and video and games become a new force due to platform like TikTok. To understand the trend in contemporary music offers not only a great commercial value but also provide us an insight into modern society and this new generation. In this project, we will employ a data driven method to depict the revolution in music industry and try to predict its future."
  },
  {
    "objectID": "introduction.html#background-research-works-done-in-this-field",
    "href": "introduction.html#background-research-works-done-in-this-field",
    "title": "An Analysis of the Trend in Today’s Music Industry",
    "section": "Background: Research Works Done in this Field",
    "text": "Background: Research Works Done in this Field\nSince the great changes in musical industry, extensive researches were done in this realm, offering us the background knowledge and valuable insights. I shall address two important publications here which provide us important background knowledge and insight on understanding today’s music trend.\n\nPublication-1: Changing Their Tune: How Consumers’ Adoption of Online Streaming Affects Music Consumption and Discovery\nThis paper throughly described how the streaming service impact the way music were consumed and user behavior. The author segment the research into three parts, first they identify the increment contribution of streaming service is contributing to the overall music consumption. Secondly, it compare the diversity in the consumers’ choice in music categories between streaming service and traditional ownership model. Finally, it researched what could impact a song’s success in the streaming environment (Datta, Knox, and Bronnenberg 2018).\nTo analysis the effects of adopting streaming service on individual music consumption, they use an anonymous third party service tracking the consumer’s platform preference and their listening behavior to create a panel of data. By applying a difference in differences (DiD) method, the authors compare the consumption differences between the group of people who adopt the streaming service and people who did not. According to their findings, adopting to streaming lead to a 49% increase of music consumption across all the platform. Furthermore listeners in streaming service tend to have a wider spectrum of music choices. The author noted it is benefit to those smaller artist to get attention but it also make the situation more competitive since the listeners now tend to discover new music instead of staying still (Datta, Knox, and Bronnenberg 2018).\n\n\nPublication-2: Tastes and Age: A Study of the Relationship between Music Tastes and Age Cohorts\nIn this paper, the author tried to investigate the impact of ages’ influence on individual music preference. The main object is to discover the relationship between then contemporary music taste and age age cohorts (Glevarec, Nowak, and Mahut 2020). The data they used for research is the ELIPSS inquiry from 2013 conducted by the Centre of Socio-Political Data in Pairs. This enquires include 13 genres of music and with a sample space of 892. The research methodology employed a regression analysis on the socio-demographic variables including age, education, profession, gender of a person and their taste of music genres. The finding reveal that for most music genres, age of the listener is the dominate factor to determine whether it will be appreciate or not. It is also noticed that people tend to rate the artist higher when they are at a similar age with the listener. Also, the author went further and point out it can be inferred from the research that people are likely to be linked to an artist they encountered during their teenager (Glevarec, Nowak, and Mahut 2020).\n\n\nOther Relevent Works:\nThere are many other researches dive into the topic of the contemporary music trends in many perspective to provide us the background of this project. The trend can be split into three aspect, the trend for music content, the trend in music consumption and the trend in music creation.\n\nTrend in Music Contents:\nIn terms of music content, current researches indicating the lyric of the songs are getting simpler and the songs with simple lyrics tend to be more successful (Varnum et al. 2021). Also, according to research, the lyrics now more likely to contain negative emotions (Brand, Acerbi, and Mesoudi 2019). This is important to notice since the research done by Borg and Hokkanen shows that lyrics plays an significant role in a music’s success (Borg and Hokkanen 2011). There are also new genres emerging, Base on the second publication summary above, we can observe the new Z generation is the key audience of those novice genres (Datta, Knox, and Bronnenberg 2018). According to Klement & Strambach, the local and extra-local knowledge source contribute to those new genres creation (Klement and Strambach 2019).\n\n\nTrend in Music Consumption:\nThe advent of streaming services has totally revolutionized music consumption as describe in the first publication’s summary. Additionally, changes also reflect on the form music been consumed. Nowadays music is often consume in combine with video or games. An good example is the TikTok. According to study, the more interactive mode in platform like TikTok short video make people foster affliction by mixing the music with image, video and text, and it is also shown as a way to self-express and connect people with similar afflictions (Vizcaı́no-Verdú and Abidin 2022).\n\n\nTrend in Music Creation:\nThere are also revolution in music creations. With more AI assistance tools emerging, even individual without traditional musical training could create songs, however it also means the standard for hit song is increasing (Liu 2019). Also the streaming service like Spotify enable artist to upload their work without the need of signing to a label. However, these technology doesn’t always promote the creation. THOMAS HODGSON described it as ‘Creative Ambivalence’ mainly caused by the opaque nature of recommending algorithm (Hodgson 2021). Artist might spend more time to align their work to the algorithm rather than being creative (Hodgson 2021)."
  },
  {
    "objectID": "introduction.html#research-goal-and-hypothesis",
    "href": "introduction.html#research-goal-and-hypothesis",
    "title": "An Analysis of the Trend in Today’s Music Industry",
    "section": "Research Goal and Hypothesis",
    "text": "Research Goal and Hypothesis\nIn this project, our aim is to provide a comprehensive, data-driven analysis of contemporary music industry trends and potentially predict its future shifts. We hypothesize that the as the Generation Z becoming the main consumer, there would be significant changes regarding the genre, rhythm and lyric of trending music. We also expect to see a trend where individual artist and artists who also from Gen Z are thriving."
  },
  {
    "objectID": "introduction.html#data-science-questions",
    "href": "introduction.html#data-science-questions",
    "title": "An Analysis of the Trend in Today’s Music Industry",
    "section": "Data Science Questions",
    "text": "Data Science Questions\nTo test our hypothesis, we shall try to answer these data driven questions:\n\nMusic Contents:\n\nWhat are the most popular genres of music today?\nHow did the popular genres changed over the three decades and is the changing rate faster or not?\nAre the songs now more homogenized than before in terms of the rhythm, lyrics and genre?\nHas the linguistic diversity in trending music becoming greater or not?\nWhat are genre or artist attract most to Generation Z?\n\n\n\nMusic Consumption:\n\nDid the consuming behavior shifted for music listeners compare with before streaming service?\nWhat is the impact of the integration between music and other media type like game and videos?\nTo what extent has the music industry been impacted by the Covid?\nAre there any common traits for those songs been made into a Sped-up remixes?\nAbout the listeners of different genres or rhythms, are they highly clustered in some trait?\n\n\n\nMusic Creation:\n\nIs it easier now to gain fame as an independent artist since AI tools make it easier to produce high quality music?\nHas there been a noticeable trend in artists archive fame younger than before?"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Tianze Yang, currently studying in Georgetown University’s DSAN Master program. I graduate from both the University of South Australia with a Bachelor’s degree in Software Engineering (Honors) and Xi’an University of Architecture and Technology in Computer Science.\nFor my internship experiences, I worked for ZhiguangHailian Big Data Technology Co., LTD, and Zhihu Inc. During these internships, I improved my skills in data processing, software development, and machine learning in real world practice. At ZhiguangHailian, I developed a Python algorithm to determine GPS coordinates from textual geographic locations and determine which district it belongs to. At Zhihu Inc., I was heavily involved into data cleaning, especially for creating training and testing set for their Large Language Model. I also had a chance to use that model create application to detect adult contents on their website.\nI also have some academic projects. I’ve worked on projects like the SA Opportunity Atlas under the guidance of Justin Anderson from MIT for my bachelor graduation. Additionally, I researched the application of AI in medical treatment under the mentorship of Dianbo Liu from Harvard University. These projects allowed me to practice a wide range of both frontend and machine learning skills. In terms of programming skills, I am proficient in programming languages Python, Java and Swift. I have experience with web development tools such as .NET, C#, Bootstrap, and Angular JS. My expertise also extends to data analysis with tools like SQL and R, and I am familiar with distributed systems like Apache Hadoop."
  },
  {
    "objectID": "about.html#self-introduction",
    "href": "about.html#self-introduction",
    "title": "About Me",
    "section": "",
    "text": "My name is Tianze Yang, currently studying in Georgetown University’s DSAN Master program. I graduate from both the University of South Australia with a Bachelor’s degree in Software Engineering (Honors) and Xi’an University of Architecture and Technology in Computer Science.\nFor my internship experiences, I worked for ZhiguangHailian Big Data Technology Co., LTD, and Zhihu Inc. During these internships, I improved my skills in data processing, software development, and machine learning in real world practice. At ZhiguangHailian, I developed a Python algorithm to determine GPS coordinates from textual geographic locations and determine which district it belongs to. At Zhihu Inc., I was heavily involved into data cleaning, especially for creating training and testing set for their Large Language Model. I also had a chance to use that model create application to detect adult contents on their website.\nI also have some academic projects. I’ve worked on projects like the SA Opportunity Atlas under the guidance of Justin Anderson from MIT for my bachelor graduation. Additionally, I researched the application of AI in medical treatment under the mentorship of Dianbo Liu from Harvard University. These projects allowed me to practice a wide range of both frontend and machine learning skills. In terms of programming skills, I am proficient in programming languages Python, Java and Swift. I have experience with web development tools such as .NET, C#, Bootstrap, and Angular JS. My expertise also extends to data analysis with tools like SQL and R, and I am familiar with distributed systems like Apache Hadoop."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n2018 - 2020: Xi’an University of Architecture and Technology, Xi’an, China Degree: Bachelor of Computer Science\n2020 - 2022: University of South Australia, Adelaide, SA Degree: Bachelor of Software Engineering (Honors)\n2023 - now: Georgetonw University, Washington, DC Program: Master of Science in Data Science and Analytics"
  },
  {
    "objectID": "about.html#academic-interests",
    "href": "about.html#academic-interests",
    "title": "About Me",
    "section": "Academic Interests",
    "text": "Academic Interests\n\nComputer Science and related diciplines\nMachine Learning\nData Scinece\nAlso want to learn more about biology if I could in the future."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Protofilio Project",
    "section": "",
    "text": "Welcome to my Protofilio Project website!"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Code",
    "section": "",
    "text": "Here is a code repository of this project in GitHub: Project Repository"
  },
  {
    "objectID": "code.html#project-repository",
    "href": "code.html#project-repository",
    "title": "Code",
    "section": "",
    "text": "Here is a code repository of this project in GitHub: Project Repository"
  },
  {
    "objectID": "data_exploration.html",
    "href": "data_exploration.html",
    "title": "Data Exploration",
    "section": "",
    "text": "In this section, we will focus on exploring the data and understanding the data. For each dataset, we will try to find interesting trait or correlation between them or across dataset in order to answer the questions we proposed and refine our hypothesis. We will use the following tools to help us in this process: Pandas and Seaborn.\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# load the data\ndf_spotify_track = pd.read_csv('../data/01-modified-data/spotify_current_all.csv')\n\n\nprint(df_spotify_track.head())\n\n   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n0         0.864   0.556    2    -7.683     0       0.1940         0.255   \n1         0.802   0.832   11    -4.107     1       0.0434         0.311   \n2         0.552   0.702    9    -5.707     1       0.1570         0.117   \n3         0.841   0.738    7    -7.455     0       0.3070         0.520   \n4         0.628   0.523   11    -8.307     0       0.0946         0.701   \n\n   instrumentalness  liveness  valence    tempo                track_id  \\\n0          0.000004    0.1120    0.726   99.974  56y1jOTK0XSvJzVv9vHQBK   \n1          0.000000    0.0815    0.890  124.997  7x9aauaA9cu6tyfpHnqDLo   \n2          0.000021    0.1050    0.564  169.994  1BxfuPKGuaTgP7aM0Bbdwr   \n3          0.000000    0.0892    0.484  169.918  5RqSsdzTNPX1uzkmlHCFvK   \n4          0.002740    0.2190    0.416  169.982  5mjYQaktjmjcMKcUIcqz4s   \n\n               artist_ids                           track_name          name  \\\n0  5cj0lLjcoR7YOSnhnX0Po5                   Paint The Town Red      Doja Cat   \n1  6HaGTQPmzraVmaVxvz6EUc  Seven (feat. Latto) (Explicit Ver.)     Jung Kook   \n2  06HL4z0CvFAxyc27GXpf02                         Cruel Summer  Taylor Swift   \n3  790FomKkXshlbRYZFtlgla                                QLONA       KAROL G   \n4  7uMDnSZyUYNBPLhPMNuaM2                            Strangers   Kenya Grace   \n\n  broad_genre  \n0         pop  \n1         pop  \n2         pop  \n3       latin  \n4      others  \n\n\nHere is a statisiical summary of the dataset for popular songs.\n\nprint(df_spotify_track.describe())\n\n       danceability      energy         key    loudness        mode  \\\ncount    187.000000  187.000000  187.000000  187.000000  187.000000   \nmean       0.652583    0.640706    5.085561   -6.201134    0.647059   \nstd        0.145082    0.164622    3.582087    2.139002    0.479168   \nmin        0.351000    0.091100    0.000000  -17.665000    0.000000   \n25%        0.541000    0.535500    1.000000   -7.515000    0.000000   \n50%        0.647000    0.669000    5.000000   -5.745000    1.000000   \n75%        0.767000    0.762500    8.000000   -4.635500    1.000000   \nmax        0.971000    0.989000   11.000000   -2.278000    1.000000   \n\n       speechiness  acousticness  instrumentalness    liveness     valence  \\\ncount   187.000000    187.000000        187.000000  187.000000  187.000000   \nmean      0.085687      0.242592          0.014381    0.168414    0.507722   \nstd       0.083841      0.247013          0.076317    0.122816    0.244540   \nmin       0.025400      0.000390          0.000000    0.029700    0.034800   \n25%       0.036750      0.048200          0.000000    0.097050    0.318500   \n50%       0.053800      0.145000          0.000000    0.120000    0.488000   \n75%       0.088300      0.405000          0.000027    0.186000    0.696500   \nmax       0.397000      0.959000          0.629000    0.923000    0.964000   \n\n            tempo  \ncount  187.000000  \nmean   122.745358  \nstd     29.703599  \nmin     66.041000  \n25%     98.516500  \n50%    122.811000  \n75%    143.019500  \nmax    203.759000  \n\n\n\n\n\nsns.countplot(x='broad_genre', data=df_spotify_track)\nplt.xticks(rotation=90)\n\nplt.show()\n\n\n\n\nFrom this plot, it’s evident that pop music dominates the current top songs, followed by hip hop as the second most popular genre. Notably, the third most prevalent category is ‘others,’ which comprises songs that don’t fit neatly into established genres. This might hint at the growing trend of genreless music. However, a comparison with older songs is necessary to determine if this is a recent phenomenon.\n\n\n\n\n\n# load the data\ndf_spotify_history = pd.read_csv('../data/01-modified-data/top50MusicFrom2010-2019_cleaned.csv')\n\n\ndf_spotify_history.head()\n\n\n\n\n\n\n\n\ntitle\nartist\ngenre\nyear\nbeat\nenergy\ndanceability\nloudness\nvalence\nduration\nacousticness\nspeechiness\npopularity\nyear_group\n\n\n\n\n0\nHey, Soul Sister\nTrain\npop\n2010\n97\n89\n67\n-4\n80\n217\n19\n4\n83\n2010-2014\n\n\n1\nLove The Way You Lie\nEminem\nhip_hop_rap\n2010\n87\n93\n75\n-5\n64\n263\n24\n23\n82\n2010-2014\n\n\n2\nTiK ToK\nKesha\npop\n2010\n120\n84\n76\n-3\n71\n200\n10\n14\n80\n2010-2014\n\n\n3\nBad Romance\nLady Gaga\npop\n2010\n119\n92\n70\n-4\n71\n295\n0\n4\n79\n2010-2014\n\n\n4\nJust the Way You Are\nBruno Mars\npop\n2010\n109\n84\n64\n-5\n43\n221\n2\n4\n78\n2010-2014\n\n\n\n\n\n\n\nStatistics summary\n\ndf_spotify_history.describe()\n\n\n\n\n\n\n\n\nyear\nbeat\nenergy\ndanceability\nloudness\nvalence\nduration\nacousticness\nspeechiness\npopularity\n\n\n\n\ncount\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n\n\nmean\n2014.592040\n118.545605\n70.504146\n64.379768\n-5.578773\n52.225539\n224.674959\n14.326700\n8.358209\n66.520730\n\n\nstd\n2.607057\n24.795358\n16.310664\n13.378718\n2.798020\n22.513020\n34.130059\n20.766165\n7.483162\n14.517746\n\n\nmin\n2010.000000\n0.000000\n0.000000\n0.000000\n-60.000000\n0.000000\n134.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n2013.000000\n100.000000\n61.000000\n57.000000\n-6.000000\n35.000000\n202.000000\n2.000000\n4.000000\n60.000000\n\n\n50%\n2015.000000\n120.000000\n74.000000\n66.000000\n-5.000000\n52.000000\n221.000000\n6.000000\n5.000000\n69.000000\n\n\n75%\n2017.000000\n129.000000\n82.000000\n73.000000\n-4.000000\n69.000000\n239.500000\n17.000000\n9.000000\n76.000000\n\n\nmax\n2019.000000\n206.000000\n98.000000\n97.000000\n-2.000000\n98.000000\n424.000000\n99.000000\n48.000000\n99.000000\n\n\n\n\n\n\n\nWe can observe from the basic statistic that most of the statistic are quite similar to the ones in the currently hot songs.\n\ndf_spotify_history.columns\n\nIndex(['title', 'artist', 'genre', 'year', 'beat', 'energy', 'danceability',\n       'loudness', 'valence', 'duration', 'acousticness', 'speechiness',\n       'popularity', 'year_group'],\n      dtype='object')\n\n\n\ndf_histroy_melted  = df_spotify_history.melt(id_vars=['title', 'artist', 'year', 'beat', 'energy', 'danceability',\n       'loudness', 'valence', 'duration', 'acousticness', 'speechiness',\n       'popularity', 'year_group'], var_name='feature', value_name='value')\n\n\nsns.countplot(x='value', data=df_histroy_melted, hue='value')\nplt.xticks(rotation=90)\n\nplt.show()\n\n\n\n\nFrom this plot, it’s evident that the past decade witnessed an overwhelming dominance of pop music, comprising nearly all of the top songs. Electronic dance music emerged as the second most successful genre, with hip hop not even ranking third in popularity. There appears to have been some significant shifts in musical trends over the past decade. To highlight these changes more clearly, we should create another graph comparing the genre proportions from the last decade with those in the current top songs.\n\n# construst the dataset\ndf1 = df_spotify_history['genre'].value_counts() / df_spotify_history['genre'].value_counts().sum()\n\ndf2 = df_spotify_track['broad_genre'].value_counts() / df_spotify_track['broad_genre'].value_counts().sum()\n\n\ndf1 = pd.DataFrame(df1)\n# df1.set_index('genre').T\n\n\ndf1\ndf1.reset_index(inplace=True)\ndf1['type'] = 'history'\n\n\ndf2 = pd.DataFrame(df2)\ndf2.reset_index(inplace=True)\ndf2['type'] = 'current'\ndf2.rename(columns={'broad_genre':'genre'}, inplace=True)\n\n\ndf_genre_compare = pd.concat([df1, df2], axis=0)\n\n\nsns.barplot(x='genre', y='count', data=df_genre_compare, hue='type')\nplt.xticks(rotation=90)\nplt.ylabel('Percentage')\nplt.show()\n\n\n\n\nThis plot contrasts the proportion of each genre in the current top songs with those from the past decade. Notably, pop music’s share has seen a substantial decline, while other genres, particularly hip hop (now the second most prevalent genre in current top songs), have witnessed a surge. A significant observation is the minimal percentage of the ‘others’ category in past top songs, which now claims a notable share. This might be attributed to the emergence of hybrid genres like ‘gauze pop’ and ‘escape room’ that don’t fit conventional classifications and have only gained recognition recently. Latin music has also experienced a resurgence. In summary, there’s been a shift in genre distribution over the years, but a more detailed time-based analysis is needed to capture the full evolution.\n\ndf_genre_change = df_spotify_history.copy()\ndf_genre_change['count'] = 0\nfor i in range(len(df_genre_change)):\n    df_genre_change['count'][i] = len(df_genre_change[df_genre_change['year'] == df_genre_change['year'][i]])\n\n\ndf_genre_change['propotion'] = 1 / df_genre_change['count']\n\n\nsns.set_theme()\n\n# Create line plots for each genre or attribute\nplt.figure(figsize=(10, 6))\nsns.lineplot(data=df_genre_change[df_genre_change['genre'] == 'pop'], x='year', y='propotion', label='Pop Proportion', estimator='sum')\nsns.lineplot(data=df_genre_change[df_genre_change['genre'] == 'hip_hop_rap'], x='year', y='propotion', label='Hip Hop Proportion', estimator='sum')\nsns.lineplot(data=df_genre_change[df_genre_change['genre'] == 'others'], x='year', y='propotion', label='Others Proportion', estimator='sum')\n# ... Add other attributes as needed\n\n# sns.lineplot(data=df_spotify_history, x='year', y='energy', label='Energy')\n\n# Add title, labels, and legend\nplt.title('Distribution of Musical Attributes Over the Years')\nplt.xlabel('Year')\nplt.ylabel('Value')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\nIn the presented plot, we observe that the proportion of pop music within top songs each year doesn’t show a consistent decline but fluctuates over time. Nonetheless, the overarching trend suggests a decrease in the popularity of pop music. Hip hop music experienced a marked drop starting in 2010, stabilizing for several years thereafter. From 2015 onwards, hip hop’s proportion began to rise again. Furthermore, the “others” category, representing emerging genres not easily classified into traditional categories, began to see an uptick starting in 2018.\n\n\n\nTo do so, we will need to see the distribution of multipy musical features in the top songs over time.\n\nsns.set_theme()\n\n# Create line plots for each genre or attribute\nplt.figure(figsize=(10, 6))\nsns.lineplot(data=df_spotify_history, x='year', y='beat', label='Beat', estimator='median')\nsns.lineplot(data=df_spotify_history, x='year', y='energy', label='Energy')\nsns.lineplot(data=df_spotify_history, x='year', y='danceability', label='Danceability')\n# ... Add other attributes as needed\n\n# sns.lineplot(data=df_spotify_history, x='year', y='energy', label='Energy')\n\n# Add title, labels, and legend\nplt.title('Distribution of Musical Attributes Over the Years')\nplt.xlabel('Year')\nplt.ylabel('Value')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\nThe preceding graph illustrates the evolution of beats, danceability, and energy distributions over a decade. The line represents the median, while the shaded area encompasses the 25th to 75th percentiles. Contrary to expectations, the distributions of these features have not become more homogeneous over time. In fact, their distributions have remained relatively consistent. Notably, the range of beats has widened compared to earlier years. Regarding median values, there is a noticeable decline in both beats and energy over the years, while danceability has seen an upward trend.\n\n\n\n\n# load the data\ndf_tik_tok = pd.read_csv('../data/01-modified-data/tik_tok_cleaned.csv')\n\n\ndf_tik_tok.head()\n\n\n\n\n\n\n\n\ntrack_name\nartist\ntrack_pop\ndanceability\nenergy\nloudness\nmode\nkey\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\ntempo\ntime_signature\nduration_ms\n\n\n\n\n0\nRunning Up That Hill (A Deal With God)\nKate Bush\n95\n0.629\n0.547\n-13.123\n0\n10\n0.0550\n0.7200\n0.003140\n0.0604\n0.197\n108.375\n4\n298933\n\n\n1\nAs It Was\nHarry Styles\n96\n0.520\n0.731\n-5.338\n0\n6\n0.0557\n0.3420\n0.001010\n0.3110\n0.662\n173.930\n4\n167303\n\n\n2\nSunroof\nNicky Youre\n44\n0.768\n0.716\n-5.110\n1\n10\n0.0404\n0.3500\n0.000000\n0.1500\n0.841\n131.430\n4\n163026\n\n\n3\nHeat Waves\nGlass Animals\n89\n0.761\n0.525\n-6.900\n1\n11\n0.0944\n0.4400\n0.000007\n0.0921\n0.531\n80.870\n4\n238805\n\n\n4\nAbout Damn Time\nLizzo\n92\n0.836\n0.743\n-6.305\n0\n10\n0.0656\n0.0995\n0.000000\n0.3350\n0.722\n108.966\n4\n191822\n\n\n\n\n\n\n\nStatistics summary\n\ndf_tik_tok.describe\n\n&lt;bound method NDFrame.describe of                                  track_name           artist  track_pop  \\\n0    Running Up That Hill (A Deal With God)        Kate Bush         95   \n1                                 As It Was     Harry Styles         96   \n2                                   Sunroof      Nicky Youre         44   \n3                                Heat Waves    Glass Animals         89   \n4                           About Damn Time            Lizzo         92   \n..                                      ...              ...        ...   \n258              The Less I Know The Better      Tame Impala         84   \n259                              Dandelions          Ruth B.         90   \n260           Jimmy Cooks (feat. 21 Savage)            Drake         92   \n261                            Good Looking  Suki Waterhouse         80   \n262                                 INFERNO        Sub Urban         71   \n\n     danceability  energy  loudness  mode  key  speechiness  acousticness  \\\n0           0.629   0.547   -13.123     0   10       0.0550      0.720000   \n1           0.520   0.731    -5.338     0    6       0.0557      0.342000   \n2           0.768   0.716    -5.110     1   10       0.0404      0.350000   \n3           0.761   0.525    -6.900     1   11       0.0944      0.440000   \n4           0.836   0.743    -6.305     0   10       0.0656      0.099500   \n..            ...     ...       ...   ...  ...          ...           ...   \n258         0.640   0.740    -4.083     1    4       0.0284      0.011500   \n259         0.609   0.692    -2.958     1    1       0.0259      0.015700   \n260         0.529   0.673    -4.711     1    0       0.1750      0.000307   \n261         0.377   0.558    -9.076     1    4       0.0299      0.078900   \n262         0.820   0.611    -5.020     0    9       0.1220      0.076600   \n\n     instrumentalness  liveness  valence    tempo  time_signature  duration_ms  \n0            0.003140    0.0604    0.197  108.375               4       298933  \n1            0.001010    0.3110    0.662  173.930               4       167303  \n2            0.000000    0.1500    0.841  131.430               4       163026  \n3            0.000007    0.0921    0.531   80.870               4       238805  \n4            0.000000    0.3350    0.722  108.966               4       191822  \n..                ...       ...      ...      ...             ...          ...  \n258          0.006780    0.1670    0.785  116.879               4       216320  \n259          0.000000    0.0864    0.454  116.959               3       233720  \n260          0.000002    0.0930    0.366  165.921               4       218365  \n261          0.000342    0.1250    0.267  149.971               3       214800  \n262          0.000025    0.0684    0.637  127.883               4       133134  \n\n[263 rows x 16 columns]&gt;\n\n\n\ndf_spotify_history.columns\n\nIndex(['title', 'artist', 'genre', 'year', 'beat', 'energy', 'danceability',\n       'loudness', 'valence', 'duration', 'acousticness', 'speechiness',\n       'popularity', 'year_group'],\n      dtype='object')\n\n\n\n# construst the dataset\ndf1 = df_spotify_track.copy()\ndf1['type'] = 'spotify'\ndf1.rename(columns={'broad_genre':'genre'}, inplace=True)\ndf2 = df_tik_tok.copy()\ndf2['type'] = 'tik_tok'\n\ndf_tik_spotify = pd.concat([df1, df2], axis=0)\n\n\ndf_tik_spotify.head()\n\n\n\n\n\n\n\n\ndanceability\nenergy\nkey\nloudness\nmode\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\n...\ntrack_id\nartist_ids\ntrack_name\nname\ngenre\ntype\nartist\ntrack_pop\ntime_signature\nduration_ms\n\n\n\n\n0\n0.864\n0.556\n2\n-7.683\n0\n0.1940\n0.255\n0.000004\n0.1120\n0.726\n...\n56y1jOTK0XSvJzVv9vHQBK\n5cj0lLjcoR7YOSnhnX0Po5\nPaint The Town Red\nDoja Cat\npop\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n1\n0.802\n0.832\n11\n-4.107\n1\n0.0434\n0.311\n0.000000\n0.0815\n0.890\n...\n7x9aauaA9cu6tyfpHnqDLo\n6HaGTQPmzraVmaVxvz6EUc\nSeven (feat. Latto) (Explicit Ver.)\nJung Kook\npop\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n2\n0.552\n0.702\n9\n-5.707\n1\n0.1570\n0.117\n0.000021\n0.1050\n0.564\n...\n1BxfuPKGuaTgP7aM0Bbdwr\n06HL4z0CvFAxyc27GXpf02\nCruel Summer\nTaylor Swift\npop\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n3\n0.841\n0.738\n7\n-7.455\n0\n0.3070\n0.520\n0.000000\n0.0892\n0.484\n...\n5RqSsdzTNPX1uzkmlHCFvK\n790FomKkXshlbRYZFtlgla\nQLONA\nKAROL G\nlatin\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n4\n0.628\n0.523\n11\n-8.307\n0\n0.0946\n0.701\n0.002740\n0.2190\n0.416\n...\n5mjYQaktjmjcMKcUIcqz4s\n7uMDnSZyUYNBPLhPMNuaM2\nStrangers\nKenya Grace\nothers\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns\n\n\n\n\nsns.scatterplot(data=df_tik_spotify, x='danceability', y='energy', hue='type')\n\n&lt;Axes: xlabel='danceability', ylabel='energy'&gt;\n\n\n\n\n\nThis scatter plot depicts the relationship between song popularity and danceability for tracks popular on TikTok versus those favored on streaming services. Songs trending on TikTok tend to cluster around higher energy and danceability levels. This may be attributed to TikTok being a short-video platform, where more energetic and danceable songs are likely to thrive. In contrast, songs popular on streaming services appear more dispersed without an evident pattern. Notably, there are outliers: highly popular songs that aren’t particularly danceable, meriting further analysis.\n\n\n\n\n# Load the data\ndf_tracks = pd.read_csv('../data/00-raw-data/tracks.csv')\n\n\ncorr_1 = df_tracks.corr(method='pearson',numeric_only=True)  \n\nmask = np.triu(np.ones_like(corr_1, dtype=bool)) \nf, ax = plt.subplots(figsize=(11, 9)) \ncmap = sns.diverging_palette(230, 20, as_cmap=True) \n\nsns.heatmap(corr_1, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\nplt.show()\n\n\n\n\nFrom the heatmap, we can discern that most variables do not exhibit strong correlations with each other. Importantly, none of the values showcase a high correlation with popularity. The features most positively correlated with popularity are loudness and energy, with both having nearly identical correlation values. On the other end, acousticness is the most negatively correlated feature, followed closely by instrumentalness. Among all the features, energy and loudness are the most closely related, which makes sense as loudness often corresponds with a song’s energy. Based on these observations, we can delve deeper into the relationship between popularity, energy, and loudness. Additionally, both danceability and loudness have a positive correlation with a song’s valence.\n\ndf_tracks['release_date'] = pd.to_datetime(df_tracks['release_date'], errors='coerce')\n\n\ndf_2010 = df_tracks[df_tracks['release_date'].dt.year &gt;= 2010]\n\n\ndf_2010['type'] = 'Others'\n\n/var/folders/s0/4jmlz4bn2jv0712y1pv_xnbh0000gn/T/ipykernel_2997/361325449.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_2010['type'] = 'Others'\n\n\n\ndf_energy = df_2010[['energy', 'type']]\ndf_energy_popular = df_spotify_history[['energy']].copy()\ndf_energy_popular['energy'] = df_energy_popular['energy'] / 100\ndf_energy_popular['type'] = 'Popular'\n\n\ndf_compare_energy = pd.concat([df_energy, df_energy_popular], axis=0)\n\n\nsns.boxplot(x=\"type\", y='energy', data=df_compare_energy)\nplt.xlabel('Popularity')\nplt.show()\n\n\n\n\nThis plot contrasts the energy distribution of top songs with that of all songs since 2010. Notably, the median energy of top songs is consistently higher than that of all songs. Furthermore, the energy of top songs tends to cluster within the 0.6-0.8 range, whereas the energy distribution for all songs is more dispersed.\n\ndf_tracks['year'] = df_tracks['release_date'].dt.year\ndf_spotify_history['energy'] = df_spotify_history['energy'] / 100 \n\n\nlen(df_tracks[df_tracks['year'] == 2010])\n\n8761\n\n\n\nlen(df_spotify_history[df_spotify_history['year'] == 2010])\n\n51\n\n\n\n# Bootstrap sampling the enegry column for each year beacuse lack of data\n\nbootstrap_samples = {'energy': [], 'year': []}\n\nfor year, group in df_spotify_history.groupby('year'):\n    for _ in range(100):  # bootstrap 100 times for each year\n        sample = group['energy'].sample(len(group), replace=True).tolist()\n        bootstrap_samples['year'] = bootstrap_samples['year'] + [year] * len(sample)\n        bootstrap_samples['energy'] = bootstrap_samples['energy'] + sample\n\n\ndf_bootstrap = pd.DataFrame(bootstrap_samples)\n\n\nsns.set_theme()\n\n# Create line plots for each genre or attribute\nplt.figure(figsize=(10, 6))\nsns.lineplot(data=df_tracks[df_tracks['year'] &gt; 2010], x='year', y='energy', label='Energy_All', estimator='median')\nsns.lineplot(data=df_bootstrap, x='year', y='energy', label='Energy_Popular', estimator='median')\n\n# sns.lineplot(data=df_spotify_history, x='year', y='loudness', label='Loudness of Popular Song', estimator='median')\n# sns.lineplot(data=df_tracks[df_tracks['year'] &gt; 2010], x='year', y='loudness', label='Loudness of All Song', estimator='median')\n\n# ... Add other attributes as needed\n\n\n# Add title, labels, and legend\nplt.title('Distribution of Musical Attributes Over the Years')\nplt.xlabel('Year')\nplt.ylabel('Energy')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\nThe plot illustrating the change in energy distribution of both top songs and other songs over the past decade offers intriguing insights. Notably, while the median energy value of top songs consistently surpasses that of all songs, this gap has been narrowing over time. Furthermore, there’s a discernible downward trend in song energy over the years. This could reflect a shift in musical preferences or a change in the characteristics of listeners.\n\n\n\n\n# load the data\ndf_listener = pd.read_csv('../data/01-modified-data/last.fm.data/users_cleaned.csv')\n\n\ndf_listener.head()\n\n\n\n\n\n\n\n\nuser_id\ncountry\nage\ngender\ncreation_time\n\n\n\n\n0\n2\nUK\n30-35\nm\n2002-10-29 01:00:00\n\n\n1\n6\nAT\n25-30\nn\n2003-07-23 02:00:00\n\n\n2\n14\nUK\n45-50\nm\n2003-02-18 21:44:13\n\n\n3\n15\nUS\n25-30\nm\n2003-02-24 03:30:33\n\n\n4\n20\nunknown\nNaN\nn\n2003-03-19 13:18:50\n\n\n\n\n\n\n\nThe dataset is mostly categroical data so there is no statistical summary for this dataset.\n\norder = df_listener['age'].value_counts().index\nsns.countplot(x='age', data=df_listener, order=order)\nplt.xticks(rotation=90)\nplt.show()\n\n\n\n\nWe are particularly interested in the age demographics. This plot reveals that the 20-25 year age group boasts the highest number of streaming users. In fact, the majority of users fall between the ages of 15 and 35. This underscores the significant influence of teenagers and Gen Z on the current streaming market.\n\n# load the data\ndf_listen_event = pd.read_csv('../data/01-modified-data/last.fm.data/listening_events_sample.csv')\n\n\n# construc the dataset\n\ndf_listen_info = df_listen_event.merge(df_listener, how='left', left_on='user_id', right_on='user_id')\n\n\n# drop the missing value\ndf_listen_info.dropna(inplace=True)\n\n\ndf_listen_info.head()\n\n\n\n\n\n\n\n\nuser_id\ntrack_id\nalbum_id\ntimestamp\ncountry\nage\ngender\ncreation_time\n\n\n\n\n0\n87459\n21395420\n17213208\n2020-02-07 12:59:11\nES\n15-20\nf\n2012-02-01 18:36:00\n\n\n1\n40265\n27546101\n20396068\n2020-01-21 16:34:24\nUS\n20-25\nf\n2009-11-15 12:17:35\n\n\n2\n29530\n32308561\n16367793\n2020-02-07 12:37:20\nBR\n20-25\nm\n2009-01-24 01:42:53\n\n\n3\n111719\n14820954\n10307272\n2020-03-07 05:32:22\nSE\n15-20\nm\n2012-05-02 23:13:26\n\n\n4\n33564\n9337136\n6639849\n2020-01-08 10:11:02\nHR\n20-25\nm\n2009-05-03 12:32:00\n\n\n\n\n\n\n\n\norder = df_listen_info['age'].value_counts().index\nsns.countplot(x='age', data=df_listen_info, order=order)\nplt.xticks(rotation=90)\nplt.ylabel('Listen Count')\nplt.show()\n\n\n\n\nFrom this graph, we can determine which group of listeners contributes to the most listening events. Interestingly, the order aligns closely with the number of consumers in each group.\n\nsns.countplot(x='gender', data=df_listener)\n\n&lt;Axes: xlabel='gender', ylabel='count'&gt;\n\n\n\n\n\nFrom this plot, it appears that males are the predominant users of the streaming service. This is somewhat surprising, as one might expect a more balanced number of male and female listeners. While there is a segment of users who do not disclose their gender, it doesn’t offset the noticeable gender imbalance.\n\nsns.countplot(x='gender', data=df_listen_info)\n\n&lt;Axes: xlabel='gender', ylabel='count'&gt;\n\n\n\n\n\nFrom the plot, it’s evident that males account for the majority of the listening events. This suggests that males are more inclined to listen to music frequently, as their representation in listening events is disproportionately higher than their actual numbers compared to females. Interestingly, individuals who choose not to disclose their gender appear to listen less frequently. Despite having a larger listener count, the number of listening events associated with this group is lower than that of females.\n\nsns.countplot(x='age', data=df_listener, hue='gender')\nplt.xticks(rotation=90)\n\n(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n [Text(0, 0, '30-35'),\n  Text(1, 0, '25-30'),\n  Text(2, 0, '45-50'),\n  Text(3, 0, '35-40'),\n  Text(4, 0, '20-25'),\n  Text(5, 0, '50-55'),\n  Text(6, 0, '40-45'),\n  Text(7, 0, '5-10'),\n  Text(8, 0, '15-20'),\n  Text(9, 0, '55-60'),\n  Text(10, 0, '60-65'),\n  Text(11, 0, '0-5'),\n  Text(12, 0, '70-75'),\n  Text(13, 0, '65-70'),\n  Text(14, 0, '10-15')])\n\n\n\n\n\nFrom the plot, it’s evident that males dominate the listener count across all age groups. Notably, the number of listeners who choose not to disclose their gender is increasingly prevalent among the 15-25 age group.\n\n# read the data\ndf_music = pd.read_csv('../data/01-modified-data/last.fm.data/tracks_cleaned.csv')\n\n\n# merge the data\ndf_listen_info_music = df_listen_info.merge(df_music, how='left', left_on='track_id', right_on='track_id')\n\n\ndf_listen_info_music.head()\n\n\n\n\n\n\n\n\nuser_id\ntrack_id\nalbum_id\ntimestamp\ncountry\nage\ngender\ncreation_time\nartist\ntrack\n\n\n\n\n0\n52710\n9299950\n16682758\n2020-02-14 09:52:25\nLT\nNaN\nf\n2010-08-18 19:52:37\nEERA\nChristine\n\n\n1\n4462\n41878638\n10034639\n2020-01-10 04:40:28\nCL\n25-30\nm\n2006-03-21 17:47:37\nLittle Mix\nTouch\n\n\n2\n43790\n38231384\n9469808\n2020-02-26 22:33:45\nIT\n15-20\nm\n2010-01-07 21:10:59\nBroken Social Scene\nSweetest Kill\n\n\n3\n62831\n18075725\n20196159\n2020-03-04 09:57:50\nID\n15-20\nm\n2011-03-20 05:19:10\nNeck Deep\nHeavy Lies\n\n\n4\n22870\n6576931\n8946033\n2020-03-10 23:50:23\nunknown\nNaN\nn\n2008-07-18 20:41:36\nImagine Dragons\nBeliever\n\n\n\n\n\n\n\n\ndf_listen_info_music.groupby('age')['artist'].apply(lambda x: x.value_counts().idxmax())\n\nage\n0-5                               米津玄師\n10-15                   Porcupine Tree\n15-20           White Noise Baby Sleep\n20-25                      Tame Impala\n25-30                          Beyoncé\n30-35                   Chris Kläfford\n35-40    Pen of Chaos et le Naheulband\n40-45                       • ukeboy •\n45-50                   The Beach Boys\n5-10                Alessandro Cortini\n50-55                       Pink Floyd\n55-60                      Count Basie\n60-65                              ДДТ\n65-70                      Ocean Grove\n70-75                          Sirenia\nName: artist, dtype: object\n\n\n\ndf_listen_info_music.groupby('age')['artist'].value_counts()['15-20']\n\nartist\nWhite Noise Baby Sleep         206\nBillie Eilish                   68\nBTS                             59\nTame Impala                     55\nGrimes                          49\n                              ... \nGodspeed You! Black Emperor      1\nGodfather of Harlem              1\nGod Help the Girl                1\nGod Dethroned                    1\nGo Radio                         1\nName: count, Length: 8445, dtype: int64\n\n\n\ndf_listen_info_music.groupby('age')['artist'].value_counts()['20-25']\n\nartist\nTame Impala      85\nRammstein        72\nDie drei ???     60\nSlipknot         60\nEminem           57\n                 ..\nKumbia Queers     1\nKumbhaka          1\nKula Shaker       1\nKuedo             1\nKubichek!         1\nName: count, Length: 13149, dtype: int64\n\n\n\ndf_listen_info_music.groupby('age')['artist'].value_counts()['25-30']\n\nartist\nBeyoncé          71\nHelene Bøksle    56\nLittle Mix       50\nAdam Sapphire    46\nDie drei ???     41\n                 ..\nAge Of Echoes     1\nAgaton Simon      1\nAgathocles        1\nAgar Agar         1\nAfterbirth        1\nName: count, Length: 7922, dtype: int64\n\n\nWhat these previous statistic is about each year group’s most played artist and their playcount. Becasue other age group has too small sample, here we only look at the three most major age group. It is interesting to see that some of the top ranked artist were not relevant to music, instead there are white noise and other sound product. It is clear that each group favors different type of aritist, though there are some overlapping. In the age group 25-30 Beyonce was the most played artist, while in the age group 20-25, it is Tame Impala. In the age group 15-20, it is Billie Eillish. This also shows how the age affect the music taste, where Beyonce was famous from the mid 1990s, and Tame Impala made their fame on 2010s while Billie Eillish was becoming golbal famous in about 2019. Apart from the affect of when the artist made their fame, it can also be observed that foreign languaage artist like BTS has ranked third in the group of age 15-20. This could be a sign of the globalization of music. It’s also interesting to see that the high ranked artist in the age group of 15-20 played most are generally cross genres, while in the age group of 25-30, the high ranked artist are more focus on a single genre.\n\n# Read the data\ndf_sound_info = pd.read_csv('../data/01-modified-data/last.fm.data/last_fm_track_info.csv')\n\n\n# merge the dataset\n\ndf_listen_sound = df_listen_info.merge(df_sound_info, how='left', left_on='track_id', right_on='track_id')\n\n\n# Drop the missing value\ndf_listen_sound.dropna(inplace=True)\n\n\ndf_listen_sound.head()\n\n\n\n\n\n\n\n\nuser_id\ntrack_id\nalbum_id\ntimestamp\ncountry\nage\ngender\ncreation_time\ndanceability\nenergy\nkey\nloudness\nmode\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\ntempo\nid\n\n\n\n\n1\n4462\n41878638\n10034639\n2020-01-10 04:40:28\nCL\n25-30\nm\n2006-03-21 17:47:37\n0.415\n0.104\n0.0\n-11.830\n1.0\n0.0426\n0.955000\n0.000004\n0.1040\n0.180\n82.006\n4g2WiijzSKzH8PApKDbadN\n\n\n2\n43790\n38231384\n9469808\n2020-02-26 22:33:45\nIT\n15-20\nm\n2010-01-07 21:10:59\n0.708\n0.384\n5.0\n-12.427\n1.0\n0.0302\n0.089300\n0.841000\n0.0961\n0.691\n87.961\n488u1IbVEsaC7fxjABWjHx\n\n\n5\n51493\n43590126\n444628\n2020-01-23 10:15:28\nUK\n20-25\nm\n2010-07-21 11:40:40\n0.486\n0.617\n5.0\n-7.115\n0.0\n0.0287\n0.095400\n0.000003\n0.1090\n0.417\n138.015\n1mea3bSkSGXuIRvnydlB5b\n\n\n13\n2194\n41200695\n19859102\n2020-03-09 19:06:27\nUK\n20-25\nm\n2005-08-22 06:45:25\n0.566\n0.869\n2.0\n-6.084\n1.0\n0.1000\n0.000916\n0.003460\n0.1140\n0.647\n178.113\n3C84jaEdYxiq8LC4jwYqj6\n\n\n21\n659\n6989555\n5566359\n2020-01-20 20:07:24\nDE\n20-25\nm\n2004-12-27 21:33:40\n0.376\n0.982\n5.0\n-3.779\n0.0\n0.0625\n0.000057\n0.000005\n0.1600\n0.150\n148.926\n6REc2Tq4G2RW5zKXtusTLF\n\n\n\n\n\n\n\n\ndf_listen_sound = df_listen_sound[(df_listen_sound['age'] == '15-20') | (df_listen_sound['age'] == '20-25') | (df_listen_sound['age'] == '25-30')]\n\n\nsns.violinplot(data=df_listen_sound, x=\"age\", y=\"tempo\")\n\n&lt;Axes: xlabel='age', ylabel='tempo'&gt;\n\n\n\n\n\n\nsns.violinplot(data=df_listen_sound, x=\"age\", y=\"danceability\")\n\n&lt;Axes: xlabel='age', ylabel='danceability'&gt;\n\n\n\n\n\nAn analysis of the previous two plots reveals insights into the preferences for danceability and energy across different age groups. For both features, the distributions for the age groups 25-30 and 20-25 exhibit similar shapes, suggesting comparable musical tastes within these age brackets. Conversely, the 15-20 age group displays a distinct pattern, characterized by a bimodal distribution with two clear peaks. This bimodality indicates diverse listening habits within this younger age bracket. Additionally, the median for the 15-20 age group is noticeably lower. A possible explanation for this deviation could be a subset of listeners in this age group who have a preference for tracks with characteristics akin to white noise which has 0 tempo and 0 danceability.\n\n\n\nIn conclusion, in this EDA process, we can gain following insight:\n\nPop music is still the king in the music, but it is losing its popularity. Hip hop is becoming more and more popular and also new genres are raising fast in the recent years.\nInstead of going more homogeneous, the popular songs are becoming more diverse in terms of some musical features include tempo and energy.\nThe tempo and energy in the popular songs are decreasing over time, while danceability is more and more popular.\nCompare with the popular songs in the streaming service, platform like tik tok prefers more energetic and danceable songs.\nThe features most positively realted to popularity is loudness, energy and explicit. The features most negatively related to popularity is acousticness and instrumentalness.\nThough energy is decreasing over time in popular songs, it is still higher than the median of overall songs. However, the gap is narrowing over time quickly.\n20-25 years old people is the age group has greatest number in streaming services, following by 15-20 years old and 25-30 years old.\nThere exist a serious unbanalce in gender of the users in streaming music services.\nPeople did not discolse their gender tend to have less listening events.\nThe music taste in different year group is noticable, even 15-20 and 20-25 has different top artist. Also, the music feature they prefer is slightly different too.\n\n\n\nBase on these conclusion from priliminary EDA, we can now refiend our hypothesis and research questions in the following way:\n\nAs the generation Z is becoming the main force of the music consumer, the music is becoming more diverse and less energetic while more danceable.\nThis could also lead to the decline of the popularity of pop music or other classic genres, instead, new genres which fuse those genres before are emerging and taking the market fast.\nGen Z will be more preferring to newer famous artists, and they are more open to music globalizaiton.\nPlatform like tik tok will be promoting more energetic and danceable songs in the future.\nIn the new generation, listeners could be clustered into more groups than before for haveing differnet music taste.\n\nIt is sure that more analysis need to be conduct after this EDA process."
  },
  {
    "objectID": "data_exploration.html#tools-used-in-data-exploration",
    "href": "data_exploration.html#tools-used-in-data-exploration",
    "title": "Data Exploration",
    "section": "",
    "text": "In this section, we will focus on exploring the data and understanding the data. For each dataset, we will try to find interesting trait or correlation between them or across dataset in order to answer the questions we proposed and refine our hypothesis. We will use the following tools to help us in this process: Pandas and Seaborn.\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# load the data\ndf_spotify_track = pd.read_csv('../data/01-modified-data/spotify_current_all.csv')\n\n\nprint(df_spotify_track.head())\n\n   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n0         0.864   0.556    2    -7.683     0       0.1940         0.255   \n1         0.802   0.832   11    -4.107     1       0.0434         0.311   \n2         0.552   0.702    9    -5.707     1       0.1570         0.117   \n3         0.841   0.738    7    -7.455     0       0.3070         0.520   \n4         0.628   0.523   11    -8.307     0       0.0946         0.701   \n\n   instrumentalness  liveness  valence    tempo                track_id  \\\n0          0.000004    0.1120    0.726   99.974  56y1jOTK0XSvJzVv9vHQBK   \n1          0.000000    0.0815    0.890  124.997  7x9aauaA9cu6tyfpHnqDLo   \n2          0.000021    0.1050    0.564  169.994  1BxfuPKGuaTgP7aM0Bbdwr   \n3          0.000000    0.0892    0.484  169.918  5RqSsdzTNPX1uzkmlHCFvK   \n4          0.002740    0.2190    0.416  169.982  5mjYQaktjmjcMKcUIcqz4s   \n\n               artist_ids                           track_name          name  \\\n0  5cj0lLjcoR7YOSnhnX0Po5                   Paint The Town Red      Doja Cat   \n1  6HaGTQPmzraVmaVxvz6EUc  Seven (feat. Latto) (Explicit Ver.)     Jung Kook   \n2  06HL4z0CvFAxyc27GXpf02                         Cruel Summer  Taylor Swift   \n3  790FomKkXshlbRYZFtlgla                                QLONA       KAROL G   \n4  7uMDnSZyUYNBPLhPMNuaM2                            Strangers   Kenya Grace   \n\n  broad_genre  \n0         pop  \n1         pop  \n2         pop  \n3       latin  \n4      others  \n\n\nHere is a statisiical summary of the dataset for popular songs.\n\nprint(df_spotify_track.describe())\n\n       danceability      energy         key    loudness        mode  \\\ncount    187.000000  187.000000  187.000000  187.000000  187.000000   \nmean       0.652583    0.640706    5.085561   -6.201134    0.647059   \nstd        0.145082    0.164622    3.582087    2.139002    0.479168   \nmin        0.351000    0.091100    0.000000  -17.665000    0.000000   \n25%        0.541000    0.535500    1.000000   -7.515000    0.000000   \n50%        0.647000    0.669000    5.000000   -5.745000    1.000000   \n75%        0.767000    0.762500    8.000000   -4.635500    1.000000   \nmax        0.971000    0.989000   11.000000   -2.278000    1.000000   \n\n       speechiness  acousticness  instrumentalness    liveness     valence  \\\ncount   187.000000    187.000000        187.000000  187.000000  187.000000   \nmean      0.085687      0.242592          0.014381    0.168414    0.507722   \nstd       0.083841      0.247013          0.076317    0.122816    0.244540   \nmin       0.025400      0.000390          0.000000    0.029700    0.034800   \n25%       0.036750      0.048200          0.000000    0.097050    0.318500   \n50%       0.053800      0.145000          0.000000    0.120000    0.488000   \n75%       0.088300      0.405000          0.000027    0.186000    0.696500   \nmax       0.397000      0.959000          0.629000    0.923000    0.964000   \n\n            tempo  \ncount  187.000000  \nmean   122.745358  \nstd     29.703599  \nmin     66.041000  \n25%     98.516500  \n50%    122.811000  \n75%    143.019500  \nmax    203.759000  \n\n\n\n\n\nsns.countplot(x='broad_genre', data=df_spotify_track)\nplt.xticks(rotation=90)\n\nplt.show()\n\n\n\n\nFrom this plot, it’s evident that pop music dominates the current top songs, followed by hip hop as the second most popular genre. Notably, the third most prevalent category is ‘others,’ which comprises songs that don’t fit neatly into established genres. This might hint at the growing trend of genreless music. However, a comparison with older songs is necessary to determine if this is a recent phenomenon.\n\n\n\n\n\n# load the data\ndf_spotify_history = pd.read_csv('../data/01-modified-data/top50MusicFrom2010-2019_cleaned.csv')\n\n\ndf_spotify_history.head()\n\n\n\n\n\n\n\n\ntitle\nartist\ngenre\nyear\nbeat\nenergy\ndanceability\nloudness\nvalence\nduration\nacousticness\nspeechiness\npopularity\nyear_group\n\n\n\n\n0\nHey, Soul Sister\nTrain\npop\n2010\n97\n89\n67\n-4\n80\n217\n19\n4\n83\n2010-2014\n\n\n1\nLove The Way You Lie\nEminem\nhip_hop_rap\n2010\n87\n93\n75\n-5\n64\n263\n24\n23\n82\n2010-2014\n\n\n2\nTiK ToK\nKesha\npop\n2010\n120\n84\n76\n-3\n71\n200\n10\n14\n80\n2010-2014\n\n\n3\nBad Romance\nLady Gaga\npop\n2010\n119\n92\n70\n-4\n71\n295\n0\n4\n79\n2010-2014\n\n\n4\nJust the Way You Are\nBruno Mars\npop\n2010\n109\n84\n64\n-5\n43\n221\n2\n4\n78\n2010-2014\n\n\n\n\n\n\n\nStatistics summary\n\ndf_spotify_history.describe()\n\n\n\n\n\n\n\n\nyear\nbeat\nenergy\ndanceability\nloudness\nvalence\nduration\nacousticness\nspeechiness\npopularity\n\n\n\n\ncount\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n603.000000\n\n\nmean\n2014.592040\n118.545605\n70.504146\n64.379768\n-5.578773\n52.225539\n224.674959\n14.326700\n8.358209\n66.520730\n\n\nstd\n2.607057\n24.795358\n16.310664\n13.378718\n2.798020\n22.513020\n34.130059\n20.766165\n7.483162\n14.517746\n\n\nmin\n2010.000000\n0.000000\n0.000000\n0.000000\n-60.000000\n0.000000\n134.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n2013.000000\n100.000000\n61.000000\n57.000000\n-6.000000\n35.000000\n202.000000\n2.000000\n4.000000\n60.000000\n\n\n50%\n2015.000000\n120.000000\n74.000000\n66.000000\n-5.000000\n52.000000\n221.000000\n6.000000\n5.000000\n69.000000\n\n\n75%\n2017.000000\n129.000000\n82.000000\n73.000000\n-4.000000\n69.000000\n239.500000\n17.000000\n9.000000\n76.000000\n\n\nmax\n2019.000000\n206.000000\n98.000000\n97.000000\n-2.000000\n98.000000\n424.000000\n99.000000\n48.000000\n99.000000\n\n\n\n\n\n\n\nWe can observe from the basic statistic that most of the statistic are quite similar to the ones in the currently hot songs.\n\ndf_spotify_history.columns\n\nIndex(['title', 'artist', 'genre', 'year', 'beat', 'energy', 'danceability',\n       'loudness', 'valence', 'duration', 'acousticness', 'speechiness',\n       'popularity', 'year_group'],\n      dtype='object')\n\n\n\ndf_histroy_melted  = df_spotify_history.melt(id_vars=['title', 'artist', 'year', 'beat', 'energy', 'danceability',\n       'loudness', 'valence', 'duration', 'acousticness', 'speechiness',\n       'popularity', 'year_group'], var_name='feature', value_name='value')\n\n\nsns.countplot(x='value', data=df_histroy_melted, hue='value')\nplt.xticks(rotation=90)\n\nplt.show()\n\n\n\n\nFrom this plot, it’s evident that the past decade witnessed an overwhelming dominance of pop music, comprising nearly all of the top songs. Electronic dance music emerged as the second most successful genre, with hip hop not even ranking third in popularity. There appears to have been some significant shifts in musical trends over the past decade. To highlight these changes more clearly, we should create another graph comparing the genre proportions from the last decade with those in the current top songs.\n\n# construst the dataset\ndf1 = df_spotify_history['genre'].value_counts() / df_spotify_history['genre'].value_counts().sum()\n\ndf2 = df_spotify_track['broad_genre'].value_counts() / df_spotify_track['broad_genre'].value_counts().sum()\n\n\ndf1 = pd.DataFrame(df1)\n# df1.set_index('genre').T\n\n\ndf1\ndf1.reset_index(inplace=True)\ndf1['type'] = 'history'\n\n\ndf2 = pd.DataFrame(df2)\ndf2.reset_index(inplace=True)\ndf2['type'] = 'current'\ndf2.rename(columns={'broad_genre':'genre'}, inplace=True)\n\n\ndf_genre_compare = pd.concat([df1, df2], axis=0)\n\n\nsns.barplot(x='genre', y='count', data=df_genre_compare, hue='type')\nplt.xticks(rotation=90)\nplt.ylabel('Percentage')\nplt.show()\n\n\n\n\nThis plot contrasts the proportion of each genre in the current top songs with those from the past decade. Notably, pop music’s share has seen a substantial decline, while other genres, particularly hip hop (now the second most prevalent genre in current top songs), have witnessed a surge. A significant observation is the minimal percentage of the ‘others’ category in past top songs, which now claims a notable share. This might be attributed to the emergence of hybrid genres like ‘gauze pop’ and ‘escape room’ that don’t fit conventional classifications and have only gained recognition recently. Latin music has also experienced a resurgence. In summary, there’s been a shift in genre distribution over the years, but a more detailed time-based analysis is needed to capture the full evolution.\n\ndf_genre_change = df_spotify_history.copy()\ndf_genre_change['count'] = 0\nfor i in range(len(df_genre_change)):\n    df_genre_change['count'][i] = len(df_genre_change[df_genre_change['year'] == df_genre_change['year'][i]])\n\n\ndf_genre_change['propotion'] = 1 / df_genre_change['count']\n\n\nsns.set_theme()\n\n# Create line plots for each genre or attribute\nplt.figure(figsize=(10, 6))\nsns.lineplot(data=df_genre_change[df_genre_change['genre'] == 'pop'], x='year', y='propotion', label='Pop Proportion', estimator='sum')\nsns.lineplot(data=df_genre_change[df_genre_change['genre'] == 'hip_hop_rap'], x='year', y='propotion', label='Hip Hop Proportion', estimator='sum')\nsns.lineplot(data=df_genre_change[df_genre_change['genre'] == 'others'], x='year', y='propotion', label='Others Proportion', estimator='sum')\n# ... Add other attributes as needed\n\n# sns.lineplot(data=df_spotify_history, x='year', y='energy', label='Energy')\n\n# Add title, labels, and legend\nplt.title('Distribution of Musical Attributes Over the Years')\nplt.xlabel('Year')\nplt.ylabel('Value')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\nIn the presented plot, we observe that the proportion of pop music within top songs each year doesn’t show a consistent decline but fluctuates over time. Nonetheless, the overarching trend suggests a decrease in the popularity of pop music. Hip hop music experienced a marked drop starting in 2010, stabilizing for several years thereafter. From 2015 onwards, hip hop’s proportion began to rise again. Furthermore, the “others” category, representing emerging genres not easily classified into traditional categories, began to see an uptick starting in 2018.\n\n\n\nTo do so, we will need to see the distribution of multipy musical features in the top songs over time.\n\nsns.set_theme()\n\n# Create line plots for each genre or attribute\nplt.figure(figsize=(10, 6))\nsns.lineplot(data=df_spotify_history, x='year', y='beat', label='Beat', estimator='median')\nsns.lineplot(data=df_spotify_history, x='year', y='energy', label='Energy')\nsns.lineplot(data=df_spotify_history, x='year', y='danceability', label='Danceability')\n# ... Add other attributes as needed\n\n# sns.lineplot(data=df_spotify_history, x='year', y='energy', label='Energy')\n\n# Add title, labels, and legend\nplt.title('Distribution of Musical Attributes Over the Years')\nplt.xlabel('Year')\nplt.ylabel('Value')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\nThe preceding graph illustrates the evolution of beats, danceability, and energy distributions over a decade. The line represents the median, while the shaded area encompasses the 25th to 75th percentiles. Contrary to expectations, the distributions of these features have not become more homogeneous over time. In fact, their distributions have remained relatively consistent. Notably, the range of beats has widened compared to earlier years. Regarding median values, there is a noticeable decline in both beats and energy over the years, while danceability has seen an upward trend.\n\n\n\n\n# load the data\ndf_tik_tok = pd.read_csv('../data/01-modified-data/tik_tok_cleaned.csv')\n\n\ndf_tik_tok.head()\n\n\n\n\n\n\n\n\ntrack_name\nartist\ntrack_pop\ndanceability\nenergy\nloudness\nmode\nkey\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\ntempo\ntime_signature\nduration_ms\n\n\n\n\n0\nRunning Up That Hill (A Deal With God)\nKate Bush\n95\n0.629\n0.547\n-13.123\n0\n10\n0.0550\n0.7200\n0.003140\n0.0604\n0.197\n108.375\n4\n298933\n\n\n1\nAs It Was\nHarry Styles\n96\n0.520\n0.731\n-5.338\n0\n6\n0.0557\n0.3420\n0.001010\n0.3110\n0.662\n173.930\n4\n167303\n\n\n2\nSunroof\nNicky Youre\n44\n0.768\n0.716\n-5.110\n1\n10\n0.0404\n0.3500\n0.000000\n0.1500\n0.841\n131.430\n4\n163026\n\n\n3\nHeat Waves\nGlass Animals\n89\n0.761\n0.525\n-6.900\n1\n11\n0.0944\n0.4400\n0.000007\n0.0921\n0.531\n80.870\n4\n238805\n\n\n4\nAbout Damn Time\nLizzo\n92\n0.836\n0.743\n-6.305\n0\n10\n0.0656\n0.0995\n0.000000\n0.3350\n0.722\n108.966\n4\n191822\n\n\n\n\n\n\n\nStatistics summary\n\ndf_tik_tok.describe\n\n&lt;bound method NDFrame.describe of                                  track_name           artist  track_pop  \\\n0    Running Up That Hill (A Deal With God)        Kate Bush         95   \n1                                 As It Was     Harry Styles         96   \n2                                   Sunroof      Nicky Youre         44   \n3                                Heat Waves    Glass Animals         89   \n4                           About Damn Time            Lizzo         92   \n..                                      ...              ...        ...   \n258              The Less I Know The Better      Tame Impala         84   \n259                              Dandelions          Ruth B.         90   \n260           Jimmy Cooks (feat. 21 Savage)            Drake         92   \n261                            Good Looking  Suki Waterhouse         80   \n262                                 INFERNO        Sub Urban         71   \n\n     danceability  energy  loudness  mode  key  speechiness  acousticness  \\\n0           0.629   0.547   -13.123     0   10       0.0550      0.720000   \n1           0.520   0.731    -5.338     0    6       0.0557      0.342000   \n2           0.768   0.716    -5.110     1   10       0.0404      0.350000   \n3           0.761   0.525    -6.900     1   11       0.0944      0.440000   \n4           0.836   0.743    -6.305     0   10       0.0656      0.099500   \n..            ...     ...       ...   ...  ...          ...           ...   \n258         0.640   0.740    -4.083     1    4       0.0284      0.011500   \n259         0.609   0.692    -2.958     1    1       0.0259      0.015700   \n260         0.529   0.673    -4.711     1    0       0.1750      0.000307   \n261         0.377   0.558    -9.076     1    4       0.0299      0.078900   \n262         0.820   0.611    -5.020     0    9       0.1220      0.076600   \n\n     instrumentalness  liveness  valence    tempo  time_signature  duration_ms  \n0            0.003140    0.0604    0.197  108.375               4       298933  \n1            0.001010    0.3110    0.662  173.930               4       167303  \n2            0.000000    0.1500    0.841  131.430               4       163026  \n3            0.000007    0.0921    0.531   80.870               4       238805  \n4            0.000000    0.3350    0.722  108.966               4       191822  \n..                ...       ...      ...      ...             ...          ...  \n258          0.006780    0.1670    0.785  116.879               4       216320  \n259          0.000000    0.0864    0.454  116.959               3       233720  \n260          0.000002    0.0930    0.366  165.921               4       218365  \n261          0.000342    0.1250    0.267  149.971               3       214800  \n262          0.000025    0.0684    0.637  127.883               4       133134  \n\n[263 rows x 16 columns]&gt;\n\n\n\ndf_spotify_history.columns\n\nIndex(['title', 'artist', 'genre', 'year', 'beat', 'energy', 'danceability',\n       'loudness', 'valence', 'duration', 'acousticness', 'speechiness',\n       'popularity', 'year_group'],\n      dtype='object')\n\n\n\n# construst the dataset\ndf1 = df_spotify_track.copy()\ndf1['type'] = 'spotify'\ndf1.rename(columns={'broad_genre':'genre'}, inplace=True)\ndf2 = df_tik_tok.copy()\ndf2['type'] = 'tik_tok'\n\ndf_tik_spotify = pd.concat([df1, df2], axis=0)\n\n\ndf_tik_spotify.head()\n\n\n\n\n\n\n\n\ndanceability\nenergy\nkey\nloudness\nmode\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\n...\ntrack_id\nartist_ids\ntrack_name\nname\ngenre\ntype\nartist\ntrack_pop\ntime_signature\nduration_ms\n\n\n\n\n0\n0.864\n0.556\n2\n-7.683\n0\n0.1940\n0.255\n0.000004\n0.1120\n0.726\n...\n56y1jOTK0XSvJzVv9vHQBK\n5cj0lLjcoR7YOSnhnX0Po5\nPaint The Town Red\nDoja Cat\npop\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n1\n0.802\n0.832\n11\n-4.107\n1\n0.0434\n0.311\n0.000000\n0.0815\n0.890\n...\n7x9aauaA9cu6tyfpHnqDLo\n6HaGTQPmzraVmaVxvz6EUc\nSeven (feat. Latto) (Explicit Ver.)\nJung Kook\npop\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n2\n0.552\n0.702\n9\n-5.707\n1\n0.1570\n0.117\n0.000021\n0.1050\n0.564\n...\n1BxfuPKGuaTgP7aM0Bbdwr\n06HL4z0CvFAxyc27GXpf02\nCruel Summer\nTaylor Swift\npop\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n3\n0.841\n0.738\n7\n-7.455\n0\n0.3070\n0.520\n0.000000\n0.0892\n0.484\n...\n5RqSsdzTNPX1uzkmlHCFvK\n790FomKkXshlbRYZFtlgla\nQLONA\nKAROL G\nlatin\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n4\n0.628\n0.523\n11\n-8.307\n0\n0.0946\n0.701\n0.002740\n0.2190\n0.416\n...\n5mjYQaktjmjcMKcUIcqz4s\n7uMDnSZyUYNBPLhPMNuaM2\nStrangers\nKenya Grace\nothers\nspotify\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 21 columns\n\n\n\n\nsns.scatterplot(data=df_tik_spotify, x='danceability', y='energy', hue='type')\n\n&lt;Axes: xlabel='danceability', ylabel='energy'&gt;\n\n\n\n\n\nThis scatter plot depicts the relationship between song popularity and danceability for tracks popular on TikTok versus those favored on streaming services. Songs trending on TikTok tend to cluster around higher energy and danceability levels. This may be attributed to TikTok being a short-video platform, where more energetic and danceable songs are likely to thrive. In contrast, songs popular on streaming services appear more dispersed without an evident pattern. Notably, there are outliers: highly popular songs that aren’t particularly danceable, meriting further analysis.\n\n\n\n\n# Load the data\ndf_tracks = pd.read_csv('../data/00-raw-data/tracks.csv')\n\n\ncorr_1 = df_tracks.corr(method='pearson',numeric_only=True)  \n\nmask = np.triu(np.ones_like(corr_1, dtype=bool)) \nf, ax = plt.subplots(figsize=(11, 9)) \ncmap = sns.diverging_palette(230, 20, as_cmap=True) \n\nsns.heatmap(corr_1, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\nplt.show()\n\n\n\n\nFrom the heatmap, we can discern that most variables do not exhibit strong correlations with each other. Importantly, none of the values showcase a high correlation with popularity. The features most positively correlated with popularity are loudness and energy, with both having nearly identical correlation values. On the other end, acousticness is the most negatively correlated feature, followed closely by instrumentalness. Among all the features, energy and loudness are the most closely related, which makes sense as loudness often corresponds with a song’s energy. Based on these observations, we can delve deeper into the relationship between popularity, energy, and loudness. Additionally, both danceability and loudness have a positive correlation with a song’s valence.\n\ndf_tracks['release_date'] = pd.to_datetime(df_tracks['release_date'], errors='coerce')\n\n\ndf_2010 = df_tracks[df_tracks['release_date'].dt.year &gt;= 2010]\n\n\ndf_2010['type'] = 'Others'\n\n/var/folders/s0/4jmlz4bn2jv0712y1pv_xnbh0000gn/T/ipykernel_2997/361325449.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_2010['type'] = 'Others'\n\n\n\ndf_energy = df_2010[['energy', 'type']]\ndf_energy_popular = df_spotify_history[['energy']].copy()\ndf_energy_popular['energy'] = df_energy_popular['energy'] / 100\ndf_energy_popular['type'] = 'Popular'\n\n\ndf_compare_energy = pd.concat([df_energy, df_energy_popular], axis=0)\n\n\nsns.boxplot(x=\"type\", y='energy', data=df_compare_energy)\nplt.xlabel('Popularity')\nplt.show()\n\n\n\n\nThis plot contrasts the energy distribution of top songs with that of all songs since 2010. Notably, the median energy of top songs is consistently higher than that of all songs. Furthermore, the energy of top songs tends to cluster within the 0.6-0.8 range, whereas the energy distribution for all songs is more dispersed.\n\ndf_tracks['year'] = df_tracks['release_date'].dt.year\ndf_spotify_history['energy'] = df_spotify_history['energy'] / 100 \n\n\nlen(df_tracks[df_tracks['year'] == 2010])\n\n8761\n\n\n\nlen(df_spotify_history[df_spotify_history['year'] == 2010])\n\n51\n\n\n\n# Bootstrap sampling the enegry column for each year beacuse lack of data\n\nbootstrap_samples = {'energy': [], 'year': []}\n\nfor year, group in df_spotify_history.groupby('year'):\n    for _ in range(100):  # bootstrap 100 times for each year\n        sample = group['energy'].sample(len(group), replace=True).tolist()\n        bootstrap_samples['year'] = bootstrap_samples['year'] + [year] * len(sample)\n        bootstrap_samples['energy'] = bootstrap_samples['energy'] + sample\n\n\ndf_bootstrap = pd.DataFrame(bootstrap_samples)\n\n\nsns.set_theme()\n\n# Create line plots for each genre or attribute\nplt.figure(figsize=(10, 6))\nsns.lineplot(data=df_tracks[df_tracks['year'] &gt; 2010], x='year', y='energy', label='Energy_All', estimator='median')\nsns.lineplot(data=df_bootstrap, x='year', y='energy', label='Energy_Popular', estimator='median')\n\n# sns.lineplot(data=df_spotify_history, x='year', y='loudness', label='Loudness of Popular Song', estimator='median')\n# sns.lineplot(data=df_tracks[df_tracks['year'] &gt; 2010], x='year', y='loudness', label='Loudness of All Song', estimator='median')\n\n# ... Add other attributes as needed\n\n\n# Add title, labels, and legend\nplt.title('Distribution of Musical Attributes Over the Years')\nplt.xlabel('Year')\nplt.ylabel('Energy')\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\nThe plot illustrating the change in energy distribution of both top songs and other songs over the past decade offers intriguing insights. Notably, while the median energy value of top songs consistently surpasses that of all songs, this gap has been narrowing over time. Furthermore, there’s a discernible downward trend in song energy over the years. This could reflect a shift in musical preferences or a change in the characteristics of listeners.\n\n\n\n\n# load the data\ndf_listener = pd.read_csv('../data/01-modified-data/last.fm.data/users_cleaned.csv')\n\n\ndf_listener.head()\n\n\n\n\n\n\n\n\nuser_id\ncountry\nage\ngender\ncreation_time\n\n\n\n\n0\n2\nUK\n30-35\nm\n2002-10-29 01:00:00\n\n\n1\n6\nAT\n25-30\nn\n2003-07-23 02:00:00\n\n\n2\n14\nUK\n45-50\nm\n2003-02-18 21:44:13\n\n\n3\n15\nUS\n25-30\nm\n2003-02-24 03:30:33\n\n\n4\n20\nunknown\nNaN\nn\n2003-03-19 13:18:50\n\n\n\n\n\n\n\nThe dataset is mostly categroical data so there is no statistical summary for this dataset.\n\norder = df_listener['age'].value_counts().index\nsns.countplot(x='age', data=df_listener, order=order)\nplt.xticks(rotation=90)\nplt.show()\n\n\n\n\nWe are particularly interested in the age demographics. This plot reveals that the 20-25 year age group boasts the highest number of streaming users. In fact, the majority of users fall between the ages of 15 and 35. This underscores the significant influence of teenagers and Gen Z on the current streaming market.\n\n# load the data\ndf_listen_event = pd.read_csv('../data/01-modified-data/last.fm.data/listening_events_sample.csv')\n\n\n# construc the dataset\n\ndf_listen_info = df_listen_event.merge(df_listener, how='left', left_on='user_id', right_on='user_id')\n\n\n# drop the missing value\ndf_listen_info.dropna(inplace=True)\n\n\ndf_listen_info.head()\n\n\n\n\n\n\n\n\nuser_id\ntrack_id\nalbum_id\ntimestamp\ncountry\nage\ngender\ncreation_time\n\n\n\n\n0\n87459\n21395420\n17213208\n2020-02-07 12:59:11\nES\n15-20\nf\n2012-02-01 18:36:00\n\n\n1\n40265\n27546101\n20396068\n2020-01-21 16:34:24\nUS\n20-25\nf\n2009-11-15 12:17:35\n\n\n2\n29530\n32308561\n16367793\n2020-02-07 12:37:20\nBR\n20-25\nm\n2009-01-24 01:42:53\n\n\n3\n111719\n14820954\n10307272\n2020-03-07 05:32:22\nSE\n15-20\nm\n2012-05-02 23:13:26\n\n\n4\n33564\n9337136\n6639849\n2020-01-08 10:11:02\nHR\n20-25\nm\n2009-05-03 12:32:00\n\n\n\n\n\n\n\n\norder = df_listen_info['age'].value_counts().index\nsns.countplot(x='age', data=df_listen_info, order=order)\nplt.xticks(rotation=90)\nplt.ylabel('Listen Count')\nplt.show()\n\n\n\n\nFrom this graph, we can determine which group of listeners contributes to the most listening events. Interestingly, the order aligns closely with the number of consumers in each group.\n\nsns.countplot(x='gender', data=df_listener)\n\n&lt;Axes: xlabel='gender', ylabel='count'&gt;\n\n\n\n\n\nFrom this plot, it appears that males are the predominant users of the streaming service. This is somewhat surprising, as one might expect a more balanced number of male and female listeners. While there is a segment of users who do not disclose their gender, it doesn’t offset the noticeable gender imbalance.\n\nsns.countplot(x='gender', data=df_listen_info)\n\n&lt;Axes: xlabel='gender', ylabel='count'&gt;\n\n\n\n\n\nFrom the plot, it’s evident that males account for the majority of the listening events. This suggests that males are more inclined to listen to music frequently, as their representation in listening events is disproportionately higher than their actual numbers compared to females. Interestingly, individuals who choose not to disclose their gender appear to listen less frequently. Despite having a larger listener count, the number of listening events associated with this group is lower than that of females.\n\nsns.countplot(x='age', data=df_listener, hue='gender')\nplt.xticks(rotation=90)\n\n(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n [Text(0, 0, '30-35'),\n  Text(1, 0, '25-30'),\n  Text(2, 0, '45-50'),\n  Text(3, 0, '35-40'),\n  Text(4, 0, '20-25'),\n  Text(5, 0, '50-55'),\n  Text(6, 0, '40-45'),\n  Text(7, 0, '5-10'),\n  Text(8, 0, '15-20'),\n  Text(9, 0, '55-60'),\n  Text(10, 0, '60-65'),\n  Text(11, 0, '0-5'),\n  Text(12, 0, '70-75'),\n  Text(13, 0, '65-70'),\n  Text(14, 0, '10-15')])\n\n\n\n\n\nFrom the plot, it’s evident that males dominate the listener count across all age groups. Notably, the number of listeners who choose not to disclose their gender is increasingly prevalent among the 15-25 age group.\n\n# read the data\ndf_music = pd.read_csv('../data/01-modified-data/last.fm.data/tracks_cleaned.csv')\n\n\n# merge the data\ndf_listen_info_music = df_listen_info.merge(df_music, how='left', left_on='track_id', right_on='track_id')\n\n\ndf_listen_info_music.head()\n\n\n\n\n\n\n\n\nuser_id\ntrack_id\nalbum_id\ntimestamp\ncountry\nage\ngender\ncreation_time\nartist\ntrack\n\n\n\n\n0\n52710\n9299950\n16682758\n2020-02-14 09:52:25\nLT\nNaN\nf\n2010-08-18 19:52:37\nEERA\nChristine\n\n\n1\n4462\n41878638\n10034639\n2020-01-10 04:40:28\nCL\n25-30\nm\n2006-03-21 17:47:37\nLittle Mix\nTouch\n\n\n2\n43790\n38231384\n9469808\n2020-02-26 22:33:45\nIT\n15-20\nm\n2010-01-07 21:10:59\nBroken Social Scene\nSweetest Kill\n\n\n3\n62831\n18075725\n20196159\n2020-03-04 09:57:50\nID\n15-20\nm\n2011-03-20 05:19:10\nNeck Deep\nHeavy Lies\n\n\n4\n22870\n6576931\n8946033\n2020-03-10 23:50:23\nunknown\nNaN\nn\n2008-07-18 20:41:36\nImagine Dragons\nBeliever\n\n\n\n\n\n\n\n\ndf_listen_info_music.groupby('age')['artist'].apply(lambda x: x.value_counts().idxmax())\n\nage\n0-5                               米津玄師\n10-15                   Porcupine Tree\n15-20           White Noise Baby Sleep\n20-25                      Tame Impala\n25-30                          Beyoncé\n30-35                   Chris Kläfford\n35-40    Pen of Chaos et le Naheulband\n40-45                       • ukeboy •\n45-50                   The Beach Boys\n5-10                Alessandro Cortini\n50-55                       Pink Floyd\n55-60                      Count Basie\n60-65                              ДДТ\n65-70                      Ocean Grove\n70-75                          Sirenia\nName: artist, dtype: object\n\n\n\ndf_listen_info_music.groupby('age')['artist'].value_counts()['15-20']\n\nartist\nWhite Noise Baby Sleep         206\nBillie Eilish                   68\nBTS                             59\nTame Impala                     55\nGrimes                          49\n                              ... \nGodspeed You! Black Emperor      1\nGodfather of Harlem              1\nGod Help the Girl                1\nGod Dethroned                    1\nGo Radio                         1\nName: count, Length: 8445, dtype: int64\n\n\n\ndf_listen_info_music.groupby('age')['artist'].value_counts()['20-25']\n\nartist\nTame Impala      85\nRammstein        72\nDie drei ???     60\nSlipknot         60\nEminem           57\n                 ..\nKumbia Queers     1\nKumbhaka          1\nKula Shaker       1\nKuedo             1\nKubichek!         1\nName: count, Length: 13149, dtype: int64\n\n\n\ndf_listen_info_music.groupby('age')['artist'].value_counts()['25-30']\n\nartist\nBeyoncé          71\nHelene Bøksle    56\nLittle Mix       50\nAdam Sapphire    46\nDie drei ???     41\n                 ..\nAge Of Echoes     1\nAgaton Simon      1\nAgathocles        1\nAgar Agar         1\nAfterbirth        1\nName: count, Length: 7922, dtype: int64\n\n\nWhat these previous statistic is about each year group’s most played artist and their playcount. Becasue other age group has too small sample, here we only look at the three most major age group. It is interesting to see that some of the top ranked artist were not relevant to music, instead there are white noise and other sound product. It is clear that each group favors different type of aritist, though there are some overlapping. In the age group 25-30 Beyonce was the most played artist, while in the age group 20-25, it is Tame Impala. In the age group 15-20, it is Billie Eillish. This also shows how the age affect the music taste, where Beyonce was famous from the mid 1990s, and Tame Impala made their fame on 2010s while Billie Eillish was becoming golbal famous in about 2019. Apart from the affect of when the artist made their fame, it can also be observed that foreign languaage artist like BTS has ranked third in the group of age 15-20. This could be a sign of the globalization of music. It’s also interesting to see that the high ranked artist in the age group of 15-20 played most are generally cross genres, while in the age group of 25-30, the high ranked artist are more focus on a single genre.\n\n# Read the data\ndf_sound_info = pd.read_csv('../data/01-modified-data/last.fm.data/last_fm_track_info.csv')\n\n\n# merge the dataset\n\ndf_listen_sound = df_listen_info.merge(df_sound_info, how='left', left_on='track_id', right_on='track_id')\n\n\n# Drop the missing value\ndf_listen_sound.dropna(inplace=True)\n\n\ndf_listen_sound.head()\n\n\n\n\n\n\n\n\nuser_id\ntrack_id\nalbum_id\ntimestamp\ncountry\nage\ngender\ncreation_time\ndanceability\nenergy\nkey\nloudness\nmode\nspeechiness\nacousticness\ninstrumentalness\nliveness\nvalence\ntempo\nid\n\n\n\n\n1\n4462\n41878638\n10034639\n2020-01-10 04:40:28\nCL\n25-30\nm\n2006-03-21 17:47:37\n0.415\n0.104\n0.0\n-11.830\n1.0\n0.0426\n0.955000\n0.000004\n0.1040\n0.180\n82.006\n4g2WiijzSKzH8PApKDbadN\n\n\n2\n43790\n38231384\n9469808\n2020-02-26 22:33:45\nIT\n15-20\nm\n2010-01-07 21:10:59\n0.708\n0.384\n5.0\n-12.427\n1.0\n0.0302\n0.089300\n0.841000\n0.0961\n0.691\n87.961\n488u1IbVEsaC7fxjABWjHx\n\n\n5\n51493\n43590126\n444628\n2020-01-23 10:15:28\nUK\n20-25\nm\n2010-07-21 11:40:40\n0.486\n0.617\n5.0\n-7.115\n0.0\n0.0287\n0.095400\n0.000003\n0.1090\n0.417\n138.015\n1mea3bSkSGXuIRvnydlB5b\n\n\n13\n2194\n41200695\n19859102\n2020-03-09 19:06:27\nUK\n20-25\nm\n2005-08-22 06:45:25\n0.566\n0.869\n2.0\n-6.084\n1.0\n0.1000\n0.000916\n0.003460\n0.1140\n0.647\n178.113\n3C84jaEdYxiq8LC4jwYqj6\n\n\n21\n659\n6989555\n5566359\n2020-01-20 20:07:24\nDE\n20-25\nm\n2004-12-27 21:33:40\n0.376\n0.982\n5.0\n-3.779\n0.0\n0.0625\n0.000057\n0.000005\n0.1600\n0.150\n148.926\n6REc2Tq4G2RW5zKXtusTLF\n\n\n\n\n\n\n\n\ndf_listen_sound = df_listen_sound[(df_listen_sound['age'] == '15-20') | (df_listen_sound['age'] == '20-25') | (df_listen_sound['age'] == '25-30')]\n\n\nsns.violinplot(data=df_listen_sound, x=\"age\", y=\"tempo\")\n\n&lt;Axes: xlabel='age', ylabel='tempo'&gt;\n\n\n\n\n\n\nsns.violinplot(data=df_listen_sound, x=\"age\", y=\"danceability\")\n\n&lt;Axes: xlabel='age', ylabel='danceability'&gt;\n\n\n\n\n\nAn analysis of the previous two plots reveals insights into the preferences for danceability and energy across different age groups. For both features, the distributions for the age groups 25-30 and 20-25 exhibit similar shapes, suggesting comparable musical tastes within these age brackets. Conversely, the 15-20 age group displays a distinct pattern, characterized by a bimodal distribution with two clear peaks. This bimodality indicates diverse listening habits within this younger age bracket. Additionally, the median for the 15-20 age group is noticeably lower. A possible explanation for this deviation could be a subset of listeners in this age group who have a preference for tracks with characteristics akin to white noise which has 0 tempo and 0 danceability.\n\n\n\nIn conclusion, in this EDA process, we can gain following insight:\n\nPop music is still the king in the music, but it is losing its popularity. Hip hop is becoming more and more popular and also new genres are raising fast in the recent years.\nInstead of going more homogeneous, the popular songs are becoming more diverse in terms of some musical features include tempo and energy.\nThe tempo and energy in the popular songs are decreasing over time, while danceability is more and more popular.\nCompare with the popular songs in the streaming service, platform like tik tok prefers more energetic and danceable songs.\nThe features most positively realted to popularity is loudness, energy and explicit. The features most negatively related to popularity is acousticness and instrumentalness.\nThough energy is decreasing over time in popular songs, it is still higher than the median of overall songs. However, the gap is narrowing over time quickly.\n20-25 years old people is the age group has greatest number in streaming services, following by 15-20 years old and 25-30 years old.\nThere exist a serious unbanalce in gender of the users in streaming music services.\nPeople did not discolse their gender tend to have less listening events.\nThe music taste in different year group is noticable, even 15-20 and 20-25 has different top artist. Also, the music feature they prefer is slightly different too.\n\n\n\nBase on these conclusion from priliminary EDA, we can now refiend our hypothesis and research questions in the following way:\n\nAs the generation Z is becoming the main force of the music consumer, the music is becoming more diverse and less energetic while more danceable.\nThis could also lead to the decline of the popularity of pop music or other classic genres, instead, new genres which fuse those genres before are emerging and taking the market fast.\nGen Z will be more preferring to newer famous artists, and they are more open to music globalizaiton.\nPlatform like tik tok will be promoting more energetic and danceable songs in the future.\nIn the new generation, listeners could be clustered into more groups than before for haveing differnet music taste.\n\nIt is sure that more analysis need to be conduct after this EDA process."
  },
  {
    "objectID": "data_garther.html",
    "href": "data_garther.html",
    "title": "Data Gathering",
    "section": "",
    "text": "In this project’s data collection phase, I will utilize an API to gather recently generated data, enhancing our ability to analyze current trends. For data that is older or unavailable through the API, I will search for already done datasets on the internet and incorporate them into this project by downloading them.\n\n\n\n\n\nTo gain insights into how the trend has evolved over the past decades, I require some historical data. Retrieving this data from the API is a bit challenging. I will need to structure the chart to encompass the changes over these decades. Fortunately, there are available datasets on the internet due to the historical nature of the data. I have downloaded information about trending music over the past decade from the following link Top 50 Spotify music dataset (from 2010 to 2019 ) The data it collected is base on Spotify audio feature API.\nDataset Name : top50MusicFrom2010-2019.csv\nBasic Information:\n\ntotal 14 columns, 603 rows\n\n\n\n\n\n\n\nColumn Name\nNon-Null Count\nDtype\n\n\n\n\ntitle\n603 non-null\nobject\n\n\nartist\n603 non-null\nobject\n\n\nthe genre of the track\n603 non-null\nobject\n\n\nyear\n603 non-null\nint64\n\n\nBeats.Per.Minute -The tempo of the song\n603 non-null\nint64\n\n\nEnergy- The energy of a song - the higher the value, the more energtic\n603 non-null\nint64\n\n\nDanceability - The higher the value, the easier it is to dance to this song\n603 non-null\nint64\n\n\nLoudness/dB - The higher the value, the louder the song\n603 non-null\nint64\n\n\nLiveness - The higher the value, the more likely the song is a live recording\n603 non-null\nint64\n\n\nValence - The higher the value, the more positive mood for the song\n603 non-null\nint64\n\n\nLength - The duration of the song\n603 non-null\nint64\n\n\nAcousticness - The higher the value the more acoustic the song is\n603 non-null\nint64\n\n\nSpeechiness - The higher the value the more spoken word the song contains\n603 non-null\nint64\n\n\nPopularity- The higher the value the more popular the song is\n603 non-null\nint64\n\n\n\nA sample of the dataset:\n\nLink to the dataset: top50MusicFrom2010-2019.csv\n\n\n\nThe TikTok Developer API has stringent application requirements that I couldn’t fulfill. Consequently, I opted to obtain data on trending music from TikTok through this link TikTok Trending Tracks This dataset comprises 263 trending songs on TikTok in the year 2022. Each song’s information was sourced from Spotify, enabling consistant analysis alongside the data collected using the Spotify API.\nDataset Name : TikTok_songs_2022.csv\nBasic Information:\n\ntotal 14 columns, 603 rows\n\n\nColumn\nNon-Null Count\nDtype\n\n\n\n\ntrack_name\n263 non-null\nobject\n\n\nartist_name\n263 non-null\nobject\n\n\nartist_pop\n263 non-null\nint64\n\n\nalbum\n263 non-null\nobject\n\n\ntrack_pop\n263 non-null\nint64\n\n\ndanceability\n263 non-null\nfloat64\n\n\nenergy\n263 non-null\nfloat64\n\n\nloudness\n263 non-null\nfloat64\n\n\nmode\n263 non-null\nint64\n\n\nkey\n263 non-null\nint64\n\n\nspeechiness\n263 non-null\nfloat64\n\n\nacousticness\n263 non-null\nfloat64\n\n\ninstrumentalness\n263 non-null\nfloat64\n\n\nliveness\n263 non-null\nfloat64\n\n\nvalence\n263 non-null\nfloat64\n\n\ntempo\n263 non-null\nfloat64\n\n\ntime_signature\n263 non-null\nint64\n\n\nduration_ms\n263 non-null\nint64\n\n\n\nA sample of the dataset:\n\nLink to the dataset: TikTok_songs_2022.csv\n\n\n\nI also required data to analyze user behaviors in order to gain insights how the musics are consumed. However, user data is often confidential and not disclosed to public. To address this, I discovered an open dataset about last.fm users listening events, which includes some anonymized user personal information. The link for this dataset is LFM-2b Dataset. This dataset comprises three key components:\nThe first component consists of three TSV files.\n\n\nOne file contains anonymized user personal information such as gender and age.\nThe second file stores track information, including track ID and artist names.\nThe third file contains details about listening events, listing each user event, including the timestamp, the user who listened to the music, and the specific track they played.\n\n\nSome of the dataset are quite messy and unable to be read directly using pandas with mix sepeartors. So I could only show the samples of the datastes here.\nDataset Name : users.tsv\nSample of the dataset: \nLink to the dataset: users.tsv\nDataset Name : tracks.tsv\nSample of the dataset:\n\nLink to the dataset: tracks.tsv\nDataset Name : listening_events.tsv\nSample of the dataset:\n\nLink to the dataset: listening_events.tsv\n\n\n\n\n\n\nTo gain a complete understanding of recent developments in the music industry and to address the more recently produced trending musics, I initiated the project by collecting data on today’s trending songs. For this purpose, I employed the Spotify API to gather music information from sources such as the ‘U.S. Top Fifty’ playlist, the Billboard Top 100, and the Billboard chart for the year 2022. The three dataset are in the same format, so I will only show the sample of one of them for the sake of brevity.\nAPI Endpoint for this sample: https://api.spotify.com/v1/playlists/6UeSakyzhiEt4NB3UAd6NQ/tracks\nDataset Name : billboard_features.csv\nBasic information:\n\ntotal 21 columns, 100 rows\n\n\nColumn\nNon-Null Count\nDtype\n\n\n\n\ndanceability\n100 non-null\nfloat64\n\n\nenergy\n100 non-null\nfloat64\n\n\nkey\n100 non-null\nint64\n\n\nloudness\n100 non-null\nfloat64\n\n\nmode\n100 non-null\nint64\n\n\nspeechiness\n100 non-null\nfloat64\n\n\nacousticness\n100 non-null\nfloat64\n\n\ninstrumentalness\n100 non-null\nfloat64\n\n\nliveness\n100 non-null\nfloat64\n\n\nvalence\n100 non-null\nfloat64\n\n\ntempo\n100 non-null\nfloat64\n\n\ntype\n100 non-null\nobject\n\n\nid\n100 non-null\nobject\n\n\nuri\n100 non-null\nobject\n\n\ntrack_href\n100 non-null\nobject\n\n\nanalysis_url\n100 non-null\nobject\n\n\nduration_ms\n100 non-null\nint64\n\n\ntime_signature\n100 non-null\nint64\n\n\nartist_ids\n100 non-null\nobject\n\n\ntrack_name\n100 non-null\nobject\n\n\n\nA sample of the dataset:\n\nLink to the dataset: billboard_features.csv\n\n\n\nAnother crucial aspect in this project is the lyric of the songs which Spotify does not provide. To address this, I used Genius API to obtain the lyrics data. Specifically, I utilized the ‘lyricsgenius’ package in Python to fetch the lyrics for each song by their names. I fetched the lyrcis for each songs in the dataset above, so there will be three lyrics dataset which follows the same format. I will only show the sample of one of them for the sake of brevity.\nDataset Name : genius_lyrics\nBasic information:\n\ntotal 3 columns, 100 rows\n\n\nColumn\nNon-Null Count\nDtype\n\n\n\n\ntrack_id\n100 non-null\nobject\n\n\nname\n100 non-null\nobject\n\n\nlyrics\n100 non-null\nobject\n\n\n\nA sample of the dataset:\n\nLink to the dataset: genius_lyrics.csv\n\n\n\nThe last.fm data, as mentioned in the previous section, provided valuable user information and activity data. However, the track data lacked audio analytical factors, consisting only of artist and track names, which is unable to conduct any meaningful analysis. To complement this, I utilized the Spotify API to search for and retrieve audio features for the music. The resulting dataset is stored in a JSON file. My plan was to collect the top 10,000 songs’ audio feature it is still under the process of collecting becasue Spotify API does have a rate limit, so it takes time to collect all the data. For now, the dataset only consist part of it, but the format is finalized.\nDataset Name : sample_track_info.json\nAPI Endpoint for searching track id: https://api.spotify.com/v1/search/track:{track_name}%20artist:{artist_name}\nAPI Endpoint for getting the audio feature: https://api.spotify.com/v1/audio-features/{track_id}\nBasic information:\n\ntotal 19 columns, 5700 rows\n\n\nColumn\nNon-Null Count\nDtype\n\n\n\n\ndanceability\n5700 non-null\nfloat64\n\n\nenergy\n5700 non-null\nfloat64\n\n\nkey\n5700 non-null\nint64\n\n\nloudness\n5700 non-null\nfloat64\n\n\nmode\n5700 non-null\nint64\n\n\nspeechiness\n5700 non-null\nfloat64\n\n\nacousticness\n5700 non-null\nfloat64\n\n\ninstrumentalness\n5700 non-null\nfloat64\n\n\nliveness\n5700 non-null\nfloat64\n\n\nvalence\n5700 non-null\nfloat64\n\n\ntempo\n5700 non-null\nfloat64\n\n\ntype\n5700 non-null\nobject\n\n\nid\n5700 non-null\nobject\n\n\nuri\n5700 non-null\nobject\n\n\ntrack_href\n5700 non-null\nobject\n\n\nanalysis_url\n5700 non-null\nobject\n\n\nduration_ms\n5700 non-null\nint64\n\n\ntime_signature\n5700 non-null\nint64\n\n\ntrack_id\n5700 non-null\nint64\n\n\n\nA sample of the dataset:\n\nLink to the dataset: sample_track_info.json"
  },
  {
    "objectID": "data_garther.html#api-data-gathering",
    "href": "data_garther.html#api-data-gathering",
    "title": "Data Gathering",
    "section": "",
    "text": "In this project’s data collection phase, I will utilize an API to gather recently generated data, enhancing our ability to analyze current trends. For data that is older or unavailable through the API, I will search for already done datasets on the internet and incorporate them into this project by downloading them.\n\n\n\n\n\nTo gain insights into how the trend has evolved over the past decades, I require some historical data. Retrieving this data from the API is a bit challenging. I will need to structure the chart to encompass the changes over these decades. Fortunately, there are available datasets on the internet due to the historical nature of the data. I have downloaded information about trending music over the past decade from the following link Top 50 Spotify music dataset (from 2010 to 2019 ) The data it collected is base on Spotify audio feature API.\nDataset Name : top50MusicFrom2010-2019.csv\nBasic Information:\n\ntotal 14 columns, 603 rows\n\n\n\n\n\n\n\nColumn Name\nNon-Null Count\nDtype\n\n\n\n\ntitle\n603 non-null\nobject\n\n\nartist\n603 non-null\nobject\n\n\nthe genre of the track\n603 non-null\nobject\n\n\nyear\n603 non-null\nint64\n\n\nBeats.Per.Minute -The tempo of the song\n603 non-null\nint64\n\n\nEnergy- The energy of a song - the higher the value, the more energtic\n603 non-null\nint64\n\n\nDanceability - The higher the value, the easier it is to dance to this song\n603 non-null\nint64\n\n\nLoudness/dB - The higher the value, the louder the song\n603 non-null\nint64\n\n\nLiveness - The higher the value, the more likely the song is a live recording\n603 non-null\nint64\n\n\nValence - The higher the value, the more positive mood for the song\n603 non-null\nint64\n\n\nLength - The duration of the song\n603 non-null\nint64\n\n\nAcousticness - The higher the value the more acoustic the song is\n603 non-null\nint64\n\n\nSpeechiness - The higher the value the more spoken word the song contains\n603 non-null\nint64\n\n\nPopularity- The higher the value the more popular the song is\n603 non-null\nint64\n\n\n\nA sample of the dataset:\n\nLink to the dataset: top50MusicFrom2010-2019.csv\n\n\n\nThe TikTok Developer API has stringent application requirements that I couldn’t fulfill. Consequently, I opted to obtain data on trending music from TikTok through this link TikTok Trending Tracks This dataset comprises 263 trending songs on TikTok in the year 2022. Each song’s information was sourced from Spotify, enabling consistant analysis alongside the data collected using the Spotify API.\nDataset Name : TikTok_songs_2022.csv\nBasic Information:\n\ntotal 14 columns, 603 rows\n\n\nColumn\nNon-Null Count\nDtype\n\n\n\n\ntrack_name\n263 non-null\nobject\n\n\nartist_name\n263 non-null\nobject\n\n\nartist_pop\n263 non-null\nint64\n\n\nalbum\n263 non-null\nobject\n\n\ntrack_pop\n263 non-null\nint64\n\n\ndanceability\n263 non-null\nfloat64\n\n\nenergy\n263 non-null\nfloat64\n\n\nloudness\n263 non-null\nfloat64\n\n\nmode\n263 non-null\nint64\n\n\nkey\n263 non-null\nint64\n\n\nspeechiness\n263 non-null\nfloat64\n\n\nacousticness\n263 non-null\nfloat64\n\n\ninstrumentalness\n263 non-null\nfloat64\n\n\nliveness\n263 non-null\nfloat64\n\n\nvalence\n263 non-null\nfloat64\n\n\ntempo\n263 non-null\nfloat64\n\n\ntime_signature\n263 non-null\nint64\n\n\nduration_ms\n263 non-null\nint64\n\n\n\nA sample of the dataset:\n\nLink to the dataset: TikTok_songs_2022.csv\n\n\n\nI also required data to analyze user behaviors in order to gain insights how the musics are consumed. However, user data is often confidential and not disclosed to public. To address this, I discovered an open dataset about last.fm users listening events, which includes some anonymized user personal information. The link for this dataset is LFM-2b Dataset. This dataset comprises three key components:\nThe first component consists of three TSV files.\n\n\nOne file contains anonymized user personal information such as gender and age.\nThe second file stores track information, including track ID and artist names.\nThe third file contains details about listening events, listing each user event, including the timestamp, the user who listened to the music, and the specific track they played.\n\n\nSome of the dataset are quite messy and unable to be read directly using pandas with mix sepeartors. So I could only show the samples of the datastes here.\nDataset Name : users.tsv\nSample of the dataset: \nLink to the dataset: users.tsv\nDataset Name : tracks.tsv\nSample of the dataset:\n\nLink to the dataset: tracks.tsv\nDataset Name : listening_events.tsv\nSample of the dataset:\n\nLink to the dataset: listening_events.tsv\n\n\n\n\n\n\nTo gain a complete understanding of recent developments in the music industry and to address the more recently produced trending musics, I initiated the project by collecting data on today’s trending songs. For this purpose, I employed the Spotify API to gather music information from sources such as the ‘U.S. Top Fifty’ playlist, the Billboard Top 100, and the Billboard chart for the year 2022. The three dataset are in the same format, so I will only show the sample of one of them for the sake of brevity.\nAPI Endpoint for this sample: https://api.spotify.com/v1/playlists/6UeSakyzhiEt4NB3UAd6NQ/tracks\nDataset Name : billboard_features.csv\nBasic information:\n\ntotal 21 columns, 100 rows\n\n\nColumn\nNon-Null Count\nDtype\n\n\n\n\ndanceability\n100 non-null\nfloat64\n\n\nenergy\n100 non-null\nfloat64\n\n\nkey\n100 non-null\nint64\n\n\nloudness\n100 non-null\nfloat64\n\n\nmode\n100 non-null\nint64\n\n\nspeechiness\n100 non-null\nfloat64\n\n\nacousticness\n100 non-null\nfloat64\n\n\ninstrumentalness\n100 non-null\nfloat64\n\n\nliveness\n100 non-null\nfloat64\n\n\nvalence\n100 non-null\nfloat64\n\n\ntempo\n100 non-null\nfloat64\n\n\ntype\n100 non-null\nobject\n\n\nid\n100 non-null\nobject\n\n\nuri\n100 non-null\nobject\n\n\ntrack_href\n100 non-null\nobject\n\n\nanalysis_url\n100 non-null\nobject\n\n\nduration_ms\n100 non-null\nint64\n\n\ntime_signature\n100 non-null\nint64\n\n\nartist_ids\n100 non-null\nobject\n\n\ntrack_name\n100 non-null\nobject\n\n\n\nA sample of the dataset:\n\nLink to the dataset: billboard_features.csv\n\n\n\nAnother crucial aspect in this project is the lyric of the songs which Spotify does not provide. To address this, I used Genius API to obtain the lyrics data. Specifically, I utilized the ‘lyricsgenius’ package in Python to fetch the lyrics for each song by their names. I fetched the lyrcis for each songs in the dataset above, so there will be three lyrics dataset which follows the same format. I will only show the sample of one of them for the sake of brevity.\nDataset Name : genius_lyrics\nBasic information:\n\ntotal 3 columns, 100 rows\n\n\nColumn\nNon-Null Count\nDtype\n\n\n\n\ntrack_id\n100 non-null\nobject\n\n\nname\n100 non-null\nobject\n\n\nlyrics\n100 non-null\nobject\n\n\n\nA sample of the dataset:\n\nLink to the dataset: genius_lyrics.csv\n\n\n\nThe last.fm data, as mentioned in the previous section, provided valuable user information and activity data. However, the track data lacked audio analytical factors, consisting only of artist and track names, which is unable to conduct any meaningful analysis. To complement this, I utilized the Spotify API to search for and retrieve audio features for the music. The resulting dataset is stored in a JSON file. My plan was to collect the top 10,000 songs’ audio feature it is still under the process of collecting becasue Spotify API does have a rate limit, so it takes time to collect all the data. For now, the dataset only consist part of it, but the format is finalized.\nDataset Name : sample_track_info.json\nAPI Endpoint for searching track id: https://api.spotify.com/v1/search/track:{track_name}%20artist:{artist_name}\nAPI Endpoint for getting the audio feature: https://api.spotify.com/v1/audio-features/{track_id}\nBasic information:\n\ntotal 19 columns, 5700 rows\n\n\nColumn\nNon-Null Count\nDtype\n\n\n\n\ndanceability\n5700 non-null\nfloat64\n\n\nenergy\n5700 non-null\nfloat64\n\n\nkey\n5700 non-null\nint64\n\n\nloudness\n5700 non-null\nfloat64\n\n\nmode\n5700 non-null\nint64\n\n\nspeechiness\n5700 non-null\nfloat64\n\n\nacousticness\n5700 non-null\nfloat64\n\n\ninstrumentalness\n5700 non-null\nfloat64\n\n\nliveness\n5700 non-null\nfloat64\n\n\nvalence\n5700 non-null\nfloat64\n\n\ntempo\n5700 non-null\nfloat64\n\n\ntype\n5700 non-null\nobject\n\n\nid\n5700 non-null\nobject\n\n\nuri\n5700 non-null\nobject\n\n\ntrack_href\n5700 non-null\nobject\n\n\nanalysis_url\n5700 non-null\nobject\n\n\nduration_ms\n5700 non-null\nint64\n\n\ntime_signature\n5700 non-null\nint64\n\n\ntrack_id\n5700 non-null\nint64\n\n\n\nA sample of the dataset:\n\nLink to the dataset: sample_track_info.json"
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "Cleaning Spotify data of current trending songs:\n\n\nFirst I merge the data from three files (global_top_50.csv, billboard_features.csv, billboard_2022_features.csv) containing recent trending music in Spotify. Because they have the same format, I just need to combine them into a data frame.\nThere are a lot of not useful colums containing various urls as shown in the picture below. Drop the unnecessary columns like time_signature, analysis_url, track_href… to lower the data dimension. Before cleaning the columns looks like this:  After cleaning, noticed all the url columns are gone: \nCheck if there are any missing values, in this case, the dataset does not contain any, like the picture below: \nIn some case there are multipy artists for For the case where a track contain more than one artiest, just leave the prominent one to keep constant with other datasets.\nAn example of multiple artists (the red words are the artist ids): \nSince we are concern about the genre information for each song, add genre column which get data from the artist dataset, using the genre information from the artist dataset spotify_artist.csv.\nColumns after adding genre information: \n\nA sample of the cleaned dataset:\n\n\n\nsample\n\n\nLink to the cleaned dataset: spotify_current_all.csv\n\n\n\nClean historical trending musics:\n\n\nFirst, I noticed the column name is too redundancy, so I changed them so they are easier to retrieve and also consistent with the previous contemporary music data.\nColumn names Before cleaning:  After cleaning: \nCheck if there are any missing values, in this case, there are no missing values \nDrop the ‘liveness’ column because it is not relevant to the music itself.\nColumns after dropping the ‘liveness’ column: \nThere are too many genres in this dataset like shown in the picture below. To make it better for analysis, I map each specific genre using regular expression and hard code mapping.\nBefore mapping:  After mapping:\n\nCreate a year binning over the year column. Make the bin width of 5 years.\nBefore binning, the year column is like this, just separate years indicate the year of the song:\n$ year        : num [1:603] 2010 2010 2010 2010 2010 2010 2010 2010 2010 2010 ... After bining, the years is turned to two groups, like shown in the picture below:\n\n\nHere is a sample of the cleaned dataset: \nLink to the cleaned dataset: top50MusicFrom2010-2019_cleaned.csv\n\n\n\nClean the artist dataset:\n\n\nThere are too many not useful columns like various urls so drop them first. Also, each artist has 8 columns of genre, to keep it consistent with other datasets, drop the genre columns and only keep the priority genre. However, the priority genre is either stored in the genres1 column or the genres column, depending on how many genres the artist have, so here I only drop the genres2 to genres8 columns.\nColumn names before dropping:\n Columns after dropping:\n\nCombine the genre1 column and genre column to create the final genre column for each artist.\nBefore cleaning (the green and red colored words are the genres, this only shows a part of the genres since it got 8 columns of genre for each artist):\n After cleaning:\n\nIt can be observe from the previous picture a lot of artist has no genre information. Fill these missing values in the genre field using the word ‘undefined’.\nAfter filling the missing values:\n\nMap the specific genre to a broader genre to reduce the number of genres. This step was done similarly to the last dataset.\nBefore mapping (there are 75 genres in total, here I onnly shows a part of them):\n After mapping:\n\n\nHere is a sample of the cleaned dataset:\n\nLink to the cleaned dataset: spotify_artist.csv\n\n\n\nClean lyrics dataset:\n\n\nMerge all the lyrics dataset (genius_lyrics_2022.csv, genius_lyrics_global.csv, genius_lyrics.csv) into one data frame.\nBy checking, there are duplicates exists, dropping all the duplicates, since there are duplicates in different trending list. Print the duplicates rows before dropping:  After dropping duplicates, use df.duplicated().sum() to check if there are any duplicates, the result should be 0.\nDrop the rows with missing lyrics, since it will serve no use in analysis.\nBefore dropping: \nAfter dropping, use df.isnull().sum() to check if there are any missing values, the result should be 0.\nRemove the indication or introduction before each song’s lyric using regular expression.\nBefore removing:\n\nAfter removing (notice the [chours] and [verse] are gone, also the lyric’s information like contributors is removed as well):\n\nRemove all the unprintable and puncuation and non-English characters since it will not be used in the analysis.\nBefore removing:\n\nAfter removing(notice the lyric only contains non-English characters are now empty):\n\nIn this picture, we can see all the punctuations are gone: \nDrop all the new empty rows using df.dropna().\nCreate a bag of word from the lyrics column using CountVectorizer and use stop_words='english' parameter to remove the stop words and drop the original lyric column.\n\nHere is a sample of the cleaned dataset:\n\nLink to the cleaned dataset: genius_lyrics_cleaned\n\n\n\nCleaning TikTok dataset\n\n\nCheck for missing value using df.isnull().sum(), there are no missing values in this dataset as shown in the picture below:\n\nCheck for duplicate value using duplicates = df_[df_tik.duplicated()], it will return a empty dataframe, showing there are no duplicates in this dataset.\nDrop not useful columns, album name and artist popularity.\nBefore dropping:\n\nAfter dropping, notice the colums dropped are gone:\n Rename the columns for better data retrieval. After rename the colums, the columns names are like this:\n\n\nHere is a sample of the cleaned dataset:\n\nLink to the cleaned dataset: tiktok_cleaned.csv\n\n\n\nClean last.fm listening events dataset\n\n\nThe listening events in the dataset are too many, 30,357,786 columns in total, which could cause trouble in analysis. So here we only randomly sample 10000 listening events from the dataset (This is just an initial decision, it could chagne as the analysis went on)\nThe columns in the dataset are squashed into one column, so i need to split it by the separator ’.\nBefore splitting:\n\nAfter splitting, notice the columns are now separated into four columns:\n\nCheck if there are any missing values in the sample dataset using colSums(is.na(df)), in this case there are no missing values in the sample dataset.\n\nHere is a sample of the cleaned dataset:\n\nLink to the cleaned dataset: listening_events_sample.csv\n\n\n\nClean last.fm track datasets\n\n\nThe data itself is encode in tsv format, but the separator is not consistent where sometime it is tab and sometimes it is spaces. So it is impossible to read directly using pandas. First, I read the file as plain text and change all the separator to comma, then save the result as a .csv file.\nBefore changing the separator: \nAfter changing the separator and save as .csv file:\n\nThere are a lot of columns in the track name are clearly unreadable, consisting of ‘!’ Or simply dots and white spaces or something like Remove all the columns only consist with these with regular expression.\nBefore removing:  After removing (notice the meaningless columns are turned to NA): \nDrop all the rows with missing values and unprintable vlaues and write the cleaned dataset to a new csv file.\n\nA sample of the cleaned dataset:\n\nLink to the cleaned dataset: tracks_cleaned.csv\n\n\n\nClean last.fm user dataset\n\n\nPlenty of users’s country information is missing, I replace all the empty value using the word ‘unknown’\nData before cleaning: \nIt is worth noticing that there are a lot of -1 ages in this dataset. It consists of 0.3% of the data. With so much missing value, whether chaning to the mean or media will introduce huge change to the variance of the data (variance dropping 23 if using media, more if using mean). So I decided the replacing of the missing value need to be done after more analysis in the next stage.\nAlso from the distribution we can see that there are very few data has age over 80, so remove them as well. This is about 0.03% of the data.\nHere is the distribution of the age in the dataset: \nUsing bining to create a 5 years range bin in the age values for better analysis.\nBefore binning, the frequency of the age is like this: \nAfter binning: \n\nHere is a sample of the cleaned dataset:\n\nLink to the cleaned dataset: users_cleaned.csv"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "The data used for this project will be host on the Georgetown Domain which can be access here: data"
  },
  {
    "objectID": "data.html#data-hosting",
    "href": "data.html#data-hosting",
    "title": "Data",
    "section": "",
    "text": "The data used for this project will be host on the Georgetown Domain which can be access here: data"
  },
  {
    "objectID": "naive_bayes_record.html",
    "href": "naive_bayes_record.html",
    "title": "Naive Bayes on Record Data",
    "section": "",
    "text": "The aim here is to use Naive Bayes to predict in which range of year the song is from base on it’s acoustic features.\n\nimport sklearn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nimport random\nfrom sklearn import metrics\n\n\nimport time\n\n\n# load data\ndata = pd.read_csv('../data/01-modified-data/top50MusicFrom2010-2019_cleaned.csv')\n\n\n# Creaet a training method\ndef train_and_test(x_train, y_train, x_test, y_test, i_print=False):\n\n    gnb = GaussianNB()\n    start = time.process_time()\n    gnb.fit(x_train, y_train)\n    end = time.process_time()\n    time_train = end - start\n    start = time.process_time()\n    y_pred = gnb.predict(x_test)\n    end = time.process_time()\n    time_eval = end - start\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracy_train = accuracy_score(y_train, gnb.predict(x_train))\n    # f1 = f1_score(y_test, y_pred, pos_label='2010-2014')\n    if i_print:\n        print(accuracy*100, accuracy_train*100) \n    \n    return accuracy_train, accuracy, time_train, time_eval\n\n\nX = data.drop(['year', 'year_group', 'genre', 'title', 'artist'], axis=1)\ny = data['year_group'].values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n\n\ntrain_and_test(X_train, y_train, X_test, y_test, i_print=True)\n\n59.50413223140496 65.56016597510373\n\n\n(0.6556016597510373,\n 0.5950413223140496,\n 0.004610999999997034,\n 0.0021029999999981897)\n\n\nWe can see the initial testing result is 59% and it’s not good enough. We will try to improve it using feature selection.\n\nN=X.shape[0]\nl = [*range(N)]       # indices\ncut = int(0.7 * N)    # 80% of the list\nrandom.shuffle(l)     # randomize\ntrain_index = l[:cut] # first 80% of shuffled list\ntest_index = l[cut:]  # last 20% of shuffled list"
  },
  {
    "objectID": "naive_bayes_record.html#implementation",
    "href": "naive_bayes_record.html#implementation",
    "title": "Naive Bayes on Record Data",
    "section": "",
    "text": "The aim here is to use Naive Bayes to predict in which range of year the song is from base on it’s acoustic features.\n\nimport sklearn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nimport random\nfrom sklearn import metrics\n\n\nimport time\n\n\n# load data\ndata = pd.read_csv('../data/01-modified-data/top50MusicFrom2010-2019_cleaned.csv')\n\n\n# Creaet a training method\ndef train_and_test(x_train, y_train, x_test, y_test, i_print=False):\n\n    gnb = GaussianNB()\n    start = time.process_time()\n    gnb.fit(x_train, y_train)\n    end = time.process_time()\n    time_train = end - start\n    start = time.process_time()\n    y_pred = gnb.predict(x_test)\n    end = time.process_time()\n    time_eval = end - start\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracy_train = accuracy_score(y_train, gnb.predict(x_train))\n    # f1 = f1_score(y_test, y_pred, pos_label='2010-2014')\n    if i_print:\n        print(accuracy*100, accuracy_train*100) \n    \n    return accuracy_train, accuracy, time_train, time_eval\n\n\nX = data.drop(['year', 'year_group', 'genre', 'title', 'artist'], axis=1)\ny = data['year_group'].values\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n\n\ntrain_and_test(X_train, y_train, X_test, y_test, i_print=True)\n\n59.50413223140496 65.56016597510373\n\n\n(0.6556016597510373,\n 0.5950413223140496,\n 0.004610999999997034,\n 0.0021029999999981897)\n\n\nWe can see the initial testing result is 59% and it’s not good enough. We will try to improve it using feature selection.\n\nN=X.shape[0]\nl = [*range(N)]       # indices\ncut = int(0.7 * N)    # 80% of the list\nrandom.shuffle(l)     # randomize\ntrain_index = l[:cut] # first 80% of shuffled list\ntest_index = l[cut:]  # last 20% of shuffled list"
  },
  {
    "objectID": "naive_bayes_record.html#feature-selection-for-record-data",
    "href": "naive_bayes_record.html#feature-selection-for-record-data",
    "title": "Naive Bayes on Record Data",
    "section": "Feature Selection for record data",
    "text": "Feature Selection for record data\nUsing a variance threshold to do feature selection\n\n# VARIANCE THRESHOLD SEARCH\n\nfrom sklearn.feature_selection import VarianceThreshold\n\nx_var=np.var(X,axis=0)\n# DEFINE GRID OF THRESHOLDS \nnum_thresholds=30\nthresholds=np.linspace(np.min(x_var),np.max(x_var),num_thresholds)\n\n# DOESN\"T WORK WELL WITH EDGE VALUES (ZERO VAR)\nthresholds=thresholds[1:-2]; #print(thresholds)\n\n# INITIALIZE ARRAYS\nnum_features=[]\ntrain_accuracies=[]\ntest_accuracies=[]\ntrain_time = []\neval_time = []\n\n#FULL TRAINING SET\n\n(acc_train,acc_test, time_train, time_eval)=train_and_test(X_train,y_train,X_test,y_test,i_print=True)\nnum_features.append(X.shape[1])\ntrain_accuracies.append(acc_train)\ntest_accuracies.append(acc_test)\ntrain_time.append(time_train)\neval_time.append(time_eval)\n\n# SEARCH FOR OPTIMAL THRESHOLD\nfor THRESHOLD in thresholds:\n    feature_selector = VarianceThreshold(threshold=THRESHOLD)\n    xtmp=feature_selector.fit_transform(X)\n    print(THRESHOLD, xtmp.shape[1])\n\n    x_train=xtmp[train_index]; y_train=y[train_index]\n    x_test=xtmp[test_index]; y_test=y[test_index]\n\n\n    (acc_train,acc_test, time_train, time_eval)=train_and_test(x_train,y_train,x_test,y_test,i_print=False)\n             \n    #RECORD \n    num_features.append(xtmp.shape[1])\n    train_accuracies.append(acc_train)\n    test_accuracies.append(acc_test)\n    train_time.append(time_train)\n    eval_time.append(time_eval)\n\n\n68.59504132231406 63.07053941908713\n47.64742517564101 8\n87.47891620223731 7\n127.31040722883361 7\n167.1418982554299 7\n206.9733892820262 6\n246.8048803086225 5\n286.6363713352188 4\n326.4678623618151 4\n366.29935338841136 4\n406.1308444150077 4\n445.962335441604 3\n485.7938264682003 3\n525.6253174947965 2\n565.4568085213929 2\n605.2882995479891 2\n645.1197905745854 1\n684.9512816011817 1\n724.782772627778 1\n764.6142636543743 1\n804.4457546809706 1\n844.2772457075669 1\n884.1087367341632 1\n923.9402277607595 1\n963.7717187873558 1\n1003.603209813952 1\n1043.4347008405484 1\n1083.2661918671447 1\n\n\n\n#UTILITY FUNCTION TO PLOT RESULTS\ndef plot_results():\n\n    #PLOT-1\n    plt.plot(num_features,train_accuracies,'-or')\n    plt.plot(num_features,test_accuracies,'-ob')\n    plt.xlabel('Number of features')\n    plt.ylabel('ACCURACY: Training (red) and Test (blue)')\n    plt.show()\n\n    # #PLOT-2\n    plt.plot(num_features,train_time,'-or')\n    plt.plot(num_features,eval_time,'-ob')\n    plt.xlabel('Number of features')\n    plt.ylabel('Runtime: training time (red) and evaluation time(blue)')\n    plt.show()\n\n    # #PLOT-3\n    plt.plot(np.array(test_accuracies),train_time,'-or')\n    plt.plot(np.array(test_accuracies),eval_time,'-ob')\n    plt.xlabel('test_accuracies')\n    plt.ylabel('Runtime: training time (red) and evaluation time (blue)')\n    plt.show()\n\n    # #PLOT-3\n    plt.plot(num_features,np.array(train_accuracies)-np.array(test_accuracies),'-or')\n    plt.xlabel('Number of features')\n    plt.ylabel('train_accuracies-test_accuracies')\n    plt.show()\n\n\nplot_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.plot(num_features,train_accuracies,'-or')\nplt.plot(num_features,test_accuracies,'-ob')\nplt.xlabel('Number of features')\nplt.ylabel('ACCURACY: Training (red) and Test (blue)')\nplt.show()\n\n\n\n\n\nimport itertools\n\n\ndef maximize_CFS(x,y):\n     \n     df_x = x\n     column_names = df_x.columns\n\n     N=X.shape[0]\n     l = [*range(N)]       # indices\n     cut = int(0.7 * N)    # 80% of the list\n     random.shuffle(l)     # randomize\n     train_index = l[:cut] # first 80% of shuffled list\n     test_index = l[cut:]  # last 20% of shuffled list\n\n     max_accuracy = 0\n     y_train=y[train_index]\n     y_test=y[test_index]\n     \n     for L in range(1,len(column_names) + 1):\n          for subset in itertools.combinations(column_names, L):\n               # print(df_x[list(subset)].values.shape)\n               temp = df_x[list(subset)]\n               x_train=temp.iloc[train_index]\n               x_test=temp.iloc[test_index]\n               _, _, accuracy, _ = train_and_test(x_train, y_train, x_test, y_test)\n               if accuracy &gt; max_accuracy:\n                    max_accuarcy = accuracy\n                    max_subset = list(subset)\n                    print(f'found new max: {max_accuarcy}  optimal features = {max_subset} \\niteration= {L}, accuarcy = {accuracy}')\n          \n     \n     return max_accuarcy, max_subset\n\n\nacc, subset = maximize_CFS(X,y)\n\nfound new max: 0.002213999999999494  optimal features = ['beat'] \niteration= 1, accuarcy = 0.002213999999999494\nfound new max: 0.0016160000000002839  optimal features = ['energy'] \niteration= 1, accuarcy = 0.0016160000000002839\nfound new max: 0.0013630000000004472  optimal features = ['danceability'] \niteration= 1, accuarcy = 0.0013630000000004472\nfound new max: 0.0016439999999997568  optimal features = ['loudness'] \niteration= 1, accuarcy = 0.0016439999999997568\nfound new max: 0.001394999999999591  optimal features = ['valence'] \niteration= 1, accuarcy = 0.001394999999999591\nfound new max: 0.0012910000000001531  optimal features = ['duration'] \niteration= 1, accuarcy = 0.0012910000000001531\nfound new max: 0.0013499999999995183  optimal features = ['acousticness'] \niteration= 1, accuarcy = 0.0013499999999995183\nfound new max: 0.001180000000000625  optimal features = ['speechiness'] \niteration= 1, accuarcy = 0.001180000000000625\nfound new max: 0.001118999999999204  optimal features = ['popularity'] \niteration= 1, accuarcy = 0.001118999999999204\nfound new max: 0.0010799999999999699  optimal features = ['beat', 'energy'] \niteration= 2, accuarcy = 0.0010799999999999699\nfound new max: 0.001056000000000168  optimal features = ['beat', 'danceability'] \niteration= 2, accuarcy = 0.001056000000000168\nfound new max: 0.001114999999999533  optimal features = ['beat', 'loudness'] \niteration= 2, accuarcy = 0.001114999999999533\nfound new max: 0.0012340000000001794  optimal features = ['beat', 'valence'] \niteration= 2, accuarcy = 0.0012340000000001794\nfound new max: 0.0010609999999999786  optimal features = ['beat', 'duration'] \niteration= 2, accuarcy = 0.0010609999999999786\nfound new max: 0.0010459999999996583  optimal features = ['beat', 'acousticness'] \niteration= 2, accuarcy = 0.0010459999999996583\nfound new max: 0.0011770000000002057  optimal features = ['beat', 'speechiness'] \niteration= 2, accuarcy = 0.0011770000000002057\nfound new max: 0.0010699999999994603  optimal features = ['beat', 'popularity'] \niteration= 2, accuarcy = 0.0010699999999994603\nfound new max: 0.0012470000000002202  optimal features = ['energy', 'danceability'] \niteration= 2, accuarcy = 0.0012470000000002202\nfound new max: 0.001056000000000168  optimal features = ['energy', 'loudness'] \niteration= 2, accuarcy = 0.001056000000000168\nfound new max: 0.0010249999999993875  optimal features = ['energy', 'valence'] \niteration= 2, accuarcy = 0.0010249999999993875\nfound new max: 0.001192000000000526  optimal features = ['energy', 'duration'] \niteration= 2, accuarcy = 0.001192000000000526\nfound new max: 0.0010339999999997573  optimal features = ['energy', 'acousticness'] \niteration= 2, accuarcy = 0.0010339999999997573\nfound new max: 0.0012879999999997338  optimal features = ['energy', 'speechiness'] \niteration= 2, accuarcy = 0.0012879999999997338\nfound new max: 0.0010969999999996816  optimal features = ['energy', 'popularity'] \niteration= 2, accuarcy = 0.0010969999999996816\nfound new max: 0.001110999999999862  optimal features = ['danceability', 'loudness'] \niteration= 2, accuarcy = 0.001110999999999862\nfound new max: 0.0017089999999999606  optimal features = ['danceability', 'valence'] \niteration= 2, accuarcy = 0.0017089999999999606\nfound new max: 0.0010890000000003397  optimal features = ['danceability', 'duration'] \niteration= 2, accuarcy = 0.0010890000000003397\nfound new max: 0.001046999999999798  optimal features = ['danceability', 'acousticness'] \niteration= 2, accuarcy = 0.001046999999999798\nfound new max: 0.0009460000000007796  optimal features = ['danceability', 'speechiness'] \niteration= 2, accuarcy = 0.0009460000000007796\nfound new max: 0.0009009999999998186  optimal features = ['danceability', 'popularity'] \niteration= 2, accuarcy = 0.0009009999999998186\nfound new max: 0.0010500000000002174  optimal features = ['loudness', 'valence'] \niteration= 2, accuarcy = 0.0010500000000002174\nfound new max: 0.0011959999999993087  optimal features = ['loudness', 'duration'] \niteration= 2, accuarcy = 0.0011959999999993087\nfound new max: 0.0010379999999994283  optimal features = ['loudness', 'acousticness'] \niteration= 2, accuarcy = 0.0010379999999994283\nfound new max: 0.0009619999999994633  optimal features = ['loudness', 'speechiness'] \niteration= 2, accuarcy = 0.0009619999999994633\nfound new max: 0.0009149999999999991  optimal features = ['loudness', 'popularity'] \niteration= 2, accuarcy = 0.0009149999999999991\nfound new max: 0.0010199999999995768  optimal features = ['valence', 'duration'] \niteration= 2, accuarcy = 0.0010199999999995768\nfound new max: 0.0011689999999999756  optimal features = ['valence', 'acousticness'] \niteration= 2, accuarcy = 0.0011689999999999756\nfound new max: 0.001008000000000564  optimal features = ['valence', 'speechiness'] \niteration= 2, accuarcy = 0.001008000000000564\nfound new max: 0.0008990000000004272  optimal features = ['valence', 'popularity'] \niteration= 2, accuarcy = 0.0008990000000004272\nfound new max: 0.0010669999999999291  optimal features = ['duration', 'acousticness'] \niteration= 2, accuarcy = 0.0010669999999999291\nfound new max: 0.001180000000000625  optimal features = ['duration', 'speechiness'] \niteration= 2, accuarcy = 0.001180000000000625\nfound new max: 0.000982999999999734  optimal features = ['duration', 'popularity'] \niteration= 2, accuarcy = 0.000982999999999734\nfound new max: 0.0008790000000002962  optimal features = ['acousticness', 'speechiness'] \niteration= 2, accuarcy = 0.0008790000000002962\nfound new max: 0.0011239999999999029  optimal features = ['acousticness', 'popularity'] \niteration= 2, accuarcy = 0.0011239999999999029\nfound new max: 0.0008960000000000079  optimal features = ['speechiness', 'popularity'] \niteration= 2, accuarcy = 0.0008960000000000079\nfound new max: 0.0009160000000001389  optimal features = ['beat', 'energy', 'danceability'] \niteration= 3, accuarcy = 0.0009160000000001389\nfound new max: 0.0008939999999997283  optimal features = ['beat', 'energy', 'loudness'] \niteration= 3, accuarcy = 0.0008939999999997283\nfound new max: 0.0009139999999998594  optimal features = ['beat', 'energy', 'valence'] \niteration= 3, accuarcy = 0.0009139999999998594\nfound new max: 0.0008949999999998681  optimal features = ['beat', 'energy', 'duration'] \niteration= 3, accuarcy = 0.0008949999999998681\nfound new max: 0.0008770000000000167  optimal features = ['beat', 'energy', 'acousticness'] \niteration= 3, accuarcy = 0.0008770000000000167\nfound new max: 0.0008780000000001564  optimal features = ['beat', 'energy', 'speechiness'] \niteration= 3, accuarcy = 0.0008780000000001564\nfound new max: 0.0010850000000006688  optimal features = ['beat', 'energy', 'popularity'] \niteration= 3, accuarcy = 0.0010850000000006688\nfound new max: 0.00091099999999944  optimal features = ['beat', 'danceability', 'loudness'] \niteration= 3, accuarcy = 0.00091099999999944\nfound new max: 0.000860000000000305  optimal features = ['beat', 'danceability', 'valence'] \niteration= 3, accuarcy = 0.000860000000000305\nfound new max: 0.0008650000000001157  optimal features = ['beat', 'danceability', 'duration'] \niteration= 3, accuarcy = 0.0008650000000001157\nfound new max: 0.0014530000000005927  optimal features = ['beat', 'danceability', 'acousticness'] \niteration= 3, accuarcy = 0.0014530000000005927\nfound new max: 0.001336000000000226  optimal features = ['beat', 'danceability', 'speechiness'] \niteration= 3, accuarcy = 0.001336000000000226\nfound new max: 0.0008980000000002875  optimal features = ['beat', 'danceability', 'popularity'] \niteration= 3, accuarcy = 0.0008980000000002875\nfound new max: 0.0008730000000003457  optimal features = ['beat', 'loudness', 'valence'] \niteration= 3, accuarcy = 0.0008730000000003457\nfound new max: 0.0008869999999996381  optimal features = ['beat', 'loudness', 'duration'] \niteration= 3, accuarcy = 0.0008869999999996381\nfound new max: 0.0010930000000000106  optimal features = ['beat', 'loudness', 'acousticness'] \niteration= 3, accuarcy = 0.0010930000000000106\nfound new max: 0.0010750000000001592  optimal features = ['beat', 'loudness', 'speechiness'] \niteration= 3, accuarcy = 0.0010750000000001592\nfound new max: 0.0008810000000005758  optimal features = ['beat', 'loudness', 'popularity'] \niteration= 3, accuarcy = 0.0008810000000005758\nfound new max: 0.0011070000000001912  optimal features = ['beat', 'valence', 'duration'] \niteration= 3, accuarcy = 0.0011070000000001912\nfound new max: 0.000904000000000238  optimal features = ['beat', 'valence', 'acousticness'] \niteration= 3, accuarcy = 0.000904000000000238\nfound new max: 0.0008599999999994168  optimal features = ['beat', 'valence', 'speechiness'] \niteration= 3, accuarcy = 0.0008599999999994168\nfound new max: 0.0010930000000000106  optimal features = ['beat', 'valence', 'popularity'] \niteration= 3, accuarcy = 0.0010930000000000106\nfound new max: 0.0011950000000000571  optimal features = ['beat', 'duration', 'acousticness'] \niteration= 3, accuarcy = 0.0011950000000000571\nfound new max: 0.0009529999999999816  optimal features = ['beat', 'duration', 'speechiness'] \niteration= 3, accuarcy = 0.0009529999999999816\nfound new max: 0.0008879999999997779  optimal features = ['beat', 'duration', 'popularity'] \niteration= 3, accuarcy = 0.0008879999999997779\nfound new max: 0.0008939999999997283  optimal features = ['beat', 'acousticness', 'speechiness'] \niteration= 3, accuarcy = 0.0008939999999997283\nfound new max: 0.0011950000000000571  optimal features = ['beat', 'acousticness', 'popularity'] \niteration= 3, accuarcy = 0.0011950000000000571\nfound new max: 0.0009390000000006893  optimal features = ['beat', 'speechiness', 'popularity'] \niteration= 3, accuarcy = 0.0009390000000006893\nfound new max: 0.0009030000000000982  optimal features = ['energy', 'danceability', 'loudness'] \niteration= 3, accuarcy = 0.0009030000000000982\nfound new max: 0.000912000000000468  optimal features = ['energy', 'danceability', 'valence'] \niteration= 3, accuarcy = 0.000912000000000468\nfound new max: 0.0010060000000002844  optimal features = ['energy', 'danceability', 'duration'] \niteration= 3, accuarcy = 0.0010060000000002844\nfound new max: 0.0008999999999996788  optimal features = ['energy', 'danceability', 'acousticness'] \niteration= 3, accuarcy = 0.0008999999999996788\nfound new max: 0.0008699999999999264  optimal features = ['energy', 'danceability', 'speechiness'] \niteration= 3, accuarcy = 0.0008699999999999264\nfound new max: 0.0008730000000003457  optimal features = ['energy', 'danceability', 'popularity'] \niteration= 3, accuarcy = 0.0008730000000003457\nfound new max: 0.000868000000000535  optimal features = ['energy', 'loudness', 'valence'] \niteration= 3, accuarcy = 0.000868000000000535\nfound new max: 0.0009630000000004912  optimal features = ['energy', 'loudness', 'duration'] \niteration= 3, accuarcy = 0.0009630000000004912\nfound new max: 0.0035349999999993997  optimal features = ['energy', 'loudness', 'acousticness'] \niteration= 3, accuarcy = 0.0035349999999993997\nfound new max: 0.0009110000000003282  optimal features = ['energy', 'loudness', 'speechiness'] \niteration= 3, accuarcy = 0.0009110000000003282\nfound new max: 0.000904000000000238  optimal features = ['energy', 'loudness', 'popularity'] \niteration= 3, accuarcy = 0.000904000000000238\nfound new max: 0.0008840000000001069  optimal features = ['energy', 'valence', 'duration'] \niteration= 3, accuarcy = 0.0008840000000001069\nfound new max: 0.000888000000000666  optimal features = ['energy', 'valence', 'acousticness'] \niteration= 3, accuarcy = 0.000888000000000666\nfound new max: 0.0011219999999996233  optimal features = ['energy', 'valence', 'speechiness'] \niteration= 3, accuarcy = 0.0011219999999996233\nfound new max: 0.000892000000000337  optimal features = ['energy', 'valence', 'popularity'] \niteration= 3, accuarcy = 0.000892000000000337\nfound new max: 0.0008660000000002555  optimal features = ['energy', 'duration', 'acousticness'] \niteration= 3, accuarcy = 0.0008660000000002555\nfound new max: 0.0011309999999999931  optimal features = ['energy', 'duration', 'speechiness'] \niteration= 3, accuarcy = 0.0011309999999999931\nfound new max: 0.0009819999999995943  optimal features = ['energy', 'duration', 'popularity'] \niteration= 3, accuarcy = 0.0009819999999995943\nfound new max: 0.0008610000000004447  optimal features = ['energy', 'acousticness', 'speechiness'] \niteration= 3, accuarcy = 0.0008610000000004447\nfound new max: 0.0008860000000003865  optimal features = ['energy', 'acousticness', 'popularity'] \niteration= 3, accuarcy = 0.0008860000000003865\nfound new max: 0.0009430000000003602  optimal features = ['energy', 'speechiness', 'popularity'] \niteration= 3, accuarcy = 0.0009430000000003602\nfound new max: 0.0009529999999999816  optimal features = ['danceability', 'loudness', 'valence'] \niteration= 3, accuarcy = 0.0009529999999999816\nfound new max: 0.0008859999999994983  optimal features = ['danceability', 'loudness', 'duration'] \niteration= 3, accuarcy = 0.0008859999999994983\nfound new max: 0.0008639999999999759  optimal features = ['danceability', 'loudness', 'acousticness'] \niteration= 3, accuarcy = 0.0008639999999999759\nfound new max: 0.0008749999999997371  optimal features = ['danceability', 'loudness', 'speechiness'] \niteration= 3, accuarcy = 0.0008749999999997371\nfound new max: 0.0009020000000008466  optimal features = ['danceability', 'loudness', 'popularity'] \niteration= 3, accuarcy = 0.0009020000000008466\nfound new max: 0.0008860000000003865  optimal features = ['danceability', 'valence', 'duration'] \niteration= 3, accuarcy = 0.0008860000000003865\nfound new max: 0.0008670000000003952  optimal features = ['danceability', 'valence', 'acousticness'] \niteration= 3, accuarcy = 0.0008670000000003952\nfound new max: 0.0009700000000005815  optimal features = ['danceability', 'valence', 'speechiness'] \niteration= 3, accuarcy = 0.0009700000000005815\nfound new max: 0.0008840000000001069  optimal features = ['danceability', 'valence', 'popularity'] \niteration= 3, accuarcy = 0.0008840000000001069\nfound new max: 0.0008819999999998274  optimal features = ['danceability', 'duration', 'acousticness'] \niteration= 3, accuarcy = 0.0008819999999998274\nfound new max: 0.0008580000000000254  optimal features = ['danceability', 'duration', 'speechiness'] \niteration= 3, accuarcy = 0.0008580000000000254\nfound new max: 0.0008780000000001564  optimal features = ['danceability', 'duration', 'popularity'] \niteration= 3, accuarcy = 0.0008780000000001564\nfound new max: 0.0008699999999999264  optimal features = ['danceability', 'acousticness', 'speechiness'] \niteration= 3, accuarcy = 0.0008699999999999264\nfound new max: 0.0008790000000002962  optimal features = ['danceability', 'acousticness', 'popularity'] \niteration= 3, accuarcy = 0.0008790000000002962\nfound new max: 0.0009069999999997691  optimal features = ['danceability', 'speechiness', 'popularity'] \niteration= 3, accuarcy = 0.0009069999999997691\nfound new max: 0.0008949999999998681  optimal features = ['loudness', 'valence', 'duration'] \niteration= 3, accuarcy = 0.0008949999999998681\nfound new max: 0.0008679999999996468  optimal features = ['loudness', 'valence', 'acousticness'] \niteration= 3, accuarcy = 0.0008679999999996468\nfound new max: 0.0008720000000002059  optimal features = ['loudness', 'valence', 'speechiness'] \niteration= 3, accuarcy = 0.0008720000000002059\nfound new max: 0.001308000000000753  optimal features = ['loudness', 'valence', 'popularity'] \niteration= 3, accuarcy = 0.001308000000000753\nfound new max: 0.0009060000000005175  optimal features = ['loudness', 'duration', 'acousticness'] \niteration= 3, accuarcy = 0.0009060000000005175\nfound new max: 0.0008770000000000167  optimal features = ['loudness', 'duration', 'speechiness'] \niteration= 3, accuarcy = 0.0008770000000000167\nfound new max: 0.0010510000000003572  optimal features = ['loudness', 'duration', 'popularity'] \niteration= 3, accuarcy = 0.0010510000000003572\nfound new max: 0.000942999999999472  optimal features = ['loudness', 'acousticness', 'speechiness'] \niteration= 3, accuarcy = 0.000942999999999472\nfound new max: 0.0009219999999992012  optimal features = ['loudness', 'acousticness', 'popularity'] \niteration= 3, accuarcy = 0.0009219999999992012\nfound new max: 0.000866999999999507  optimal features = ['loudness', 'speechiness', 'popularity'] \niteration= 3, accuarcy = 0.000866999999999507\nfound new max: 0.0011890000000001066  optimal features = ['valence', 'duration', 'acousticness'] \niteration= 3, accuarcy = 0.0011890000000001066\nfound new max: 0.0011209999999994835  optimal features = ['valence', 'duration', 'speechiness'] \niteration= 3, accuarcy = 0.0011209999999994835\nfound new max: 0.0009189999999996701  optimal features = ['valence', 'duration', 'popularity'] \niteration= 3, accuarcy = 0.0009189999999996701\nfound new max: 0.0008790000000002962  optimal features = ['valence', 'acousticness', 'speechiness'] \niteration= 3, accuarcy = 0.0008790000000002962\nfound new max: 0.0009649999999998826  optimal features = ['valence', 'acousticness', 'popularity'] \niteration= 3, accuarcy = 0.0009649999999998826\nfound new max: 0.0009819999999995943  optimal features = ['valence', 'speechiness', 'popularity'] \niteration= 3, accuarcy = 0.0009819999999995943\nfound new max: 0.0012089999999993495  optimal features = ['duration', 'acousticness', 'speechiness'] \niteration= 3, accuarcy = 0.0012089999999993495\nfound new max: 0.0010010000000004737  optimal features = ['duration', 'acousticness', 'popularity'] \niteration= 3, accuarcy = 0.0010010000000004737\nfound new max: 0.0009439999999996118  optimal features = ['duration', 'speechiness', 'popularity'] \niteration= 3, accuarcy = 0.0009439999999996118\nfound new max: 0.0008710000000000662  optimal features = ['acousticness', 'speechiness', 'popularity'] \niteration= 3, accuarcy = 0.0008710000000000662\nfound new max: 0.0008690000000006748  optimal features = ['beat', 'energy', 'danceability', 'loudness'] \niteration= 4, accuarcy = 0.0008690000000006748\nfound new max: 0.0010110000000000952  optimal features = ['beat', 'energy', 'danceability', 'valence'] \niteration= 4, accuarcy = 0.0010110000000000952\nfound new max: 0.0009039999999993498  optimal features = ['beat', 'energy', 'danceability', 'duration'] \niteration= 4, accuarcy = 0.0009039999999993498\nfound new max: 0.0009430000000003602  optimal features = ['beat', 'energy', 'danceability', 'acousticness'] \niteration= 4, accuarcy = 0.0009430000000003602\nfound new max: 0.0008759999999998769  optimal features = ['beat', 'energy', 'danceability', 'speechiness'] \niteration= 4, accuarcy = 0.0008759999999998769\nfound new max: 0.000904000000000238  optimal features = ['beat', 'energy', 'danceability', 'popularity'] \niteration= 4, accuarcy = 0.000904000000000238\nfound new max: 0.0009639999999997428  optimal features = ['beat', 'energy', 'loudness', 'valence'] \niteration= 4, accuarcy = 0.0009639999999997428\nfound new max: 0.00091099999999944  optimal features = ['beat', 'energy', 'loudness', 'duration'] \niteration= 4, accuarcy = 0.00091099999999944\nfound new max: 0.0009220000000000894  optimal features = ['beat', 'energy', 'loudness', 'acousticness'] \niteration= 4, accuarcy = 0.0009220000000000894\nfound new max: 0.0011099999999997223  optimal features = ['beat', 'energy', 'loudness', 'speechiness'] \niteration= 4, accuarcy = 0.0011099999999997223\nfound new max: 0.0008980000000002875  optimal features = ['beat', 'energy', 'loudness', 'popularity'] \niteration= 4, accuarcy = 0.0008980000000002875\nfound new max: 0.0008670000000003952  optimal features = ['beat', 'energy', 'valence', 'duration'] \niteration= 4, accuarcy = 0.0008670000000003952\nfound new max: 0.0009580000000006805  optimal features = ['beat', 'energy', 'valence', 'acousticness'] \niteration= 4, accuarcy = 0.0009580000000006805\nfound new max: 0.0008749999999997371  optimal features = ['beat', 'energy', 'valence', 'speechiness'] \niteration= 4, accuarcy = 0.0008749999999997371\nfound new max: 0.0008940000000006165  optimal features = ['beat', 'energy', 'valence', 'popularity'] \niteration= 4, accuarcy = 0.0008940000000006165\nfound new max: 0.000900000000000567  optimal features = ['beat', 'energy', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.000900000000000567\nfound new max: 0.0008639999999999759  optimal features = ['beat', 'energy', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.0008639999999999759\nfound new max: 0.0009220000000000894  optimal features = ['beat', 'energy', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.0009220000000000894\nfound new max: 0.0008749999999997371  optimal features = ['beat', 'energy', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0008749999999997371\nfound new max: 0.0008659999999993673  optimal features = ['beat', 'energy', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0008659999999993673\nfound new max: 0.0009170000000002787  optimal features = ['beat', 'energy', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0009170000000002787\nfound new max: 0.0008850000000002467  optimal features = ['beat', 'danceability', 'loudness', 'valence'] \niteration= 4, accuarcy = 0.0008850000000002467\nfound new max: 0.0008840000000001069  optimal features = ['beat', 'danceability', 'loudness', 'duration'] \niteration= 4, accuarcy = 0.0008840000000001069\nfound new max: 0.0008879999999997779  optimal features = ['beat', 'danceability', 'loudness', 'acousticness'] \niteration= 4, accuarcy = 0.0008879999999997779\nfound new max: 0.0008770000000000167  optimal features = ['beat', 'danceability', 'loudness', 'speechiness'] \niteration= 4, accuarcy = 0.0008770000000000167\nfound new max: 0.0011260000000001824  optimal features = ['beat', 'danceability', 'loudness', 'popularity'] \niteration= 4, accuarcy = 0.0011260000000001824\nfound new max: 0.0009110000000003282  optimal features = ['beat', 'danceability', 'valence', 'duration'] \niteration= 4, accuarcy = 0.0009110000000003282\nfound new max: 0.0008720000000002059  optimal features = ['beat', 'danceability', 'valence', 'acousticness'] \niteration= 4, accuarcy = 0.0008720000000002059\nfound new max: 0.0008840000000001069  optimal features = ['beat', 'danceability', 'valence', 'speechiness'] \niteration= 4, accuarcy = 0.0008840000000001069\nfound new max: 0.0008779999999992683  optimal features = ['beat', 'danceability', 'valence', 'popularity'] \niteration= 4, accuarcy = 0.0008779999999992683\nfound new max: 0.0008810000000005758  optimal features = ['beat', 'danceability', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.0008810000000005758\nfound new max: 0.0008590000000001652  optimal features = ['beat', 'danceability', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.0008590000000001652\nfound new max: 0.0010070000000004242  optimal features = ['beat', 'danceability', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.0010070000000004242\nfound new max: 0.0009299999999994313  optimal features = ['beat', 'danceability', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0009299999999994313\nfound new max: 0.0008679999999996468  optimal features = ['beat', 'danceability', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0008679999999996468\nfound new max: 0.000856000000000634  optimal features = ['beat', 'danceability', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.000856000000000634\nfound new max: 0.0009410000000000807  optimal features = ['beat', 'loudness', 'valence', 'duration'] \niteration= 4, accuarcy = 0.0009410000000000807\nfound new max: 0.0008929999999995886  optimal features = ['beat', 'loudness', 'valence', 'acousticness'] \niteration= 4, accuarcy = 0.0008929999999995886\nfound new max: 0.0008730000000003457  optimal features = ['beat', 'loudness', 'valence', 'speechiness'] \niteration= 4, accuarcy = 0.0008730000000003457\nfound new max: 0.0009339999999999904  optimal features = ['beat', 'loudness', 'valence', 'popularity'] \niteration= 4, accuarcy = 0.0009339999999999904\nfound new max: 0.0008999999999996788  optimal features = ['beat', 'loudness', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.0008999999999996788\nfound new max: 0.0009589999999999321  optimal features = ['beat', 'loudness', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.0009589999999999321\nfound new max: 0.0009119999999995798  optimal features = ['beat', 'loudness', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.0009119999999995798\nfound new max: 0.0008779999999992683  optimal features = ['beat', 'loudness', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0008779999999992683\nfound new max: 0.0009009999999998186  optimal features = ['beat', 'loudness', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0009009999999998186\nfound new max: 0.0008930000000004767  optimal features = ['beat', 'loudness', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0008930000000004767\nfound new max: 0.0008710000000000662  optimal features = ['beat', 'valence', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.0008710000000000662\nfound new max: 0.000904000000000238  optimal features = ['beat', 'valence', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.000904000000000238\nfound new max: 0.0008699999999999264  optimal features = ['beat', 'valence', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.0008699999999999264\nfound new max: 0.0008979999999993993  optimal features = ['beat', 'valence', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0008979999999993993\nfound new max: 0.000860000000000305  optimal features = ['beat', 'valence', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.000860000000000305\nfound new max: 0.0009250000000005087  optimal features = ['beat', 'valence', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0009250000000005087\nfound new max: 0.0009019999999999584  optimal features = ['beat', 'duration', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0009019999999999584\nfound new max: 0.0008679999999996468  optimal features = ['beat', 'duration', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0008679999999996468\nfound new max: 0.0008650000000001157  optimal features = ['beat', 'duration', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0008650000000001157\nfound new max: 0.0011919999999996378  optimal features = ['beat', 'acousticness', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0011919999999996378\nfound new max: 0.0013350000000000861  optimal features = ['energy', 'danceability', 'loudness', 'valence'] \niteration= 4, accuarcy = 0.0013350000000000861\nfound new max: 0.0009249999999996206  optimal features = ['energy', 'danceability', 'loudness', 'duration'] \niteration= 4, accuarcy = 0.0009249999999996206\nfound new max: 0.0008910000000001972  optimal features = ['energy', 'danceability', 'loudness', 'acousticness'] \niteration= 4, accuarcy = 0.0008910000000001972\nfound new max: 0.0009069999999997691  optimal features = ['energy', 'danceability', 'loudness', 'speechiness'] \niteration= 4, accuarcy = 0.0009069999999997691\nfound new max: 0.0010289999999999466  optimal features = ['energy', 'danceability', 'loudness', 'popularity'] \niteration= 4, accuarcy = 0.0010289999999999466\nfound new max: 0.0010529999999997486  optimal features = ['energy', 'danceability', 'valence', 'duration'] \niteration= 4, accuarcy = 0.0010529999999997486\nfound new max: 0.0009420000000002204  optimal features = ['energy', 'danceability', 'valence', 'acousticness'] \niteration= 4, accuarcy = 0.0009420000000002204\nfound new max: 0.000892000000000337  optimal features = ['energy', 'danceability', 'valence', 'speechiness'] \niteration= 4, accuarcy = 0.000892000000000337\nfound new max: 0.0008739999999995973  optimal features = ['energy', 'danceability', 'valence', 'popularity'] \niteration= 4, accuarcy = 0.0008739999999995973\nfound new max: 0.001210999999999629  optimal features = ['energy', 'danceability', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.001210999999999629\nfound new max: 0.0009220000000000894  optimal features = ['energy', 'danceability', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.0009220000000000894\nfound new max: 0.0008790000000002962  optimal features = ['energy', 'danceability', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.0008790000000002962\nfound new max: 0.0010790000000007183  optimal features = ['energy', 'danceability', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0010790000000007183\nfound new max: 0.000932000000000599  optimal features = ['energy', 'danceability', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.000932000000000599\nfound new max: 0.0008869999999996381  optimal features = ['energy', 'danceability', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0008869999999996381\nfound new max: 0.0008710000000000662  optimal features = ['energy', 'loudness', 'valence', 'duration'] \niteration= 4, accuarcy = 0.0008710000000000662\nfound new max: 0.0010419999999999874  optimal features = ['energy', 'loudness', 'valence', 'acousticness'] \niteration= 4, accuarcy = 0.0010419999999999874\nfound new max: 0.0008819999999998274  optimal features = ['energy', 'loudness', 'valence', 'speechiness'] \niteration= 4, accuarcy = 0.0008819999999998274\nfound new max: 0.0008829999999999671  optimal features = ['energy', 'loudness', 'valence', 'popularity'] \niteration= 4, accuarcy = 0.0008829999999999671\nfound new max: 0.001068000000000069  optimal features = ['energy', 'loudness', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.001068000000000069\nfound new max: 0.0009060000000005175  optimal features = ['energy', 'loudness', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.0009060000000005175\nfound new max: 0.000888000000000666  optimal features = ['energy', 'loudness', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.000888000000000666\nfound new max: 0.0008729999999994575  optimal features = ['energy', 'loudness', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0008729999999994575\nfound new max: 0.0008499999999997954  optimal features = ['energy', 'loudness', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0008499999999997954\nfound new max: 0.0008580000000000254  optimal features = ['energy', 'loudness', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0008580000000000254\nfound new max: 0.0008900000000000574  optimal features = ['energy', 'valence', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.0008900000000000574\nfound new max: 0.0008790000000002962  optimal features = ['energy', 'valence', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.0008790000000002962\nfound new max: 0.0008620000000005845  optimal features = ['energy', 'valence', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.0008620000000005845\nfound new max: 0.0009370000000004097  optimal features = ['energy', 'valence', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0009370000000004097\nfound new max: 0.0009350000000001302  optimal features = ['energy', 'valence', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0009350000000001302\nfound new max: 0.0010570000000003077  optimal features = ['energy', 'valence', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0010570000000003077\nfound new max: 0.0009079999999999089  optimal features = ['energy', 'duration', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0009079999999999089\nfound new max: 0.0009039999999993498  optimal features = ['energy', 'duration', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0009039999999993498\nfound new max: 0.0009430000000003602  optimal features = ['energy', 'duration', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0009430000000003602\nfound new max: 0.0009769999999997836  optimal features = ['energy', 'acousticness', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0009769999999997836\nfound new max: 0.0010229999999999961  optimal features = ['danceability', 'loudness', 'valence', 'duration'] \niteration= 4, accuarcy = 0.0010229999999999961\nfound new max: 0.0010740000000000194  optimal features = ['danceability', 'loudness', 'valence', 'acousticness'] \niteration= 4, accuarcy = 0.0010740000000000194\nfound new max: 0.0009290000000001797  optimal features = ['danceability', 'loudness', 'valence', 'speechiness'] \niteration= 4, accuarcy = 0.0009290000000001797\nfound new max: 0.0009179999999995303  optimal features = ['danceability', 'loudness', 'valence', 'popularity'] \niteration= 4, accuarcy = 0.0009179999999995303\nfound new max: 0.0009809999999994545  optimal features = ['danceability', 'loudness', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.0009809999999994545\nfound new max: 0.0010300000000000864  optimal features = ['danceability', 'loudness', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.0010300000000000864\nfound new max: 0.0008660000000002555  optimal features = ['danceability', 'loudness', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.0008660000000002555\nfound new max: 0.0008879999999997779  optimal features = ['danceability', 'loudness', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0008879999999997779\nfound new max: 0.0011559999999999349  optimal features = ['danceability', 'loudness', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0011559999999999349\nfound new max: 0.0009289999999992915  optimal features = ['danceability', 'loudness', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0009289999999992915\nfound new max: 0.0008850000000002467  optimal features = ['danceability', 'valence', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.0008850000000002467\nfound new max: 0.0009329999999998506  optimal features = ['danceability', 'valence', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.0009329999999998506\nfound new max: 0.0009529999999999816  optimal features = ['danceability', 'valence', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.0009529999999999816\nfound new max: 0.0008569999999998856  optimal features = ['danceability', 'valence', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0008569999999998856\nfound new max: 0.000900000000000567  optimal features = ['danceability', 'valence', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.000900000000000567\nfound new max: 0.0011449999999992855  optimal features = ['danceability', 'valence', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0011449999999992855\nfound new max: 0.0008970000000001477  optimal features = ['danceability', 'duration', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0008970000000001477\nfound new max: 0.0010830000000003892  optimal features = ['danceability', 'duration', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0010830000000003892\nfound new max: 0.0009449999999997516  optimal features = ['danceability', 'duration', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0009449999999997516\nfound new max: 0.0010089999999998156  optimal features = ['danceability', 'acousticness', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0010089999999998156\nfound new max: 0.0008949999999998681  optimal features = ['loudness', 'valence', 'duration', 'acousticness'] \niteration= 4, accuarcy = 0.0008949999999998681\nfound new max: 0.0009779999999999234  optimal features = ['loudness', 'valence', 'duration', 'speechiness'] \niteration= 4, accuarcy = 0.0009779999999999234\nfound new max: 0.0010659999999997893  optimal features = ['loudness', 'valence', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.0010659999999997893\nfound new max: 0.0011619999999998853  optimal features = ['loudness', 'valence', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0011619999999998853\nfound new max: 0.0010550000000000281  optimal features = ['loudness', 'valence', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0010550000000000281\nfound new max: 0.0010989999999999611  optimal features = ['loudness', 'valence', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0010989999999999611\nfound new max: 0.0012840000000000629  optimal features = ['loudness', 'duration', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0012840000000000629\nfound new max: 0.0013860000000001094  optimal features = ['loudness', 'duration', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.0013860000000001094\nfound new max: 0.0014769999999995065  optimal features = ['loudness', 'duration', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0014769999999995065\nfound new max: 0.00091099999999944  optimal features = ['loudness', 'acousticness', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.00091099999999944\nfound new max: 0.0009619999999994633  optimal features = ['valence', 'duration', 'acousticness', 'speechiness'] \niteration= 4, accuarcy = 0.0009619999999994633\nfound new max: 0.000892000000000337  optimal features = ['valence', 'duration', 'acousticness', 'popularity'] \niteration= 4, accuarcy = 0.000892000000000337\nfound new max: 0.0010870000000000601  optimal features = ['valence', 'duration', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.0010870000000000601\nfound new max: 0.001020000000000465  optimal features = ['valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.001020000000000465\nfound new max: 0.000912000000000468  optimal features = ['duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 4, accuarcy = 0.000912000000000468\nfound new max: 0.0013190000000005142  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence'] \niteration= 5, accuarcy = 0.0013190000000005142\nfound new max: 0.0009899999999998244  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'duration'] \niteration= 5, accuarcy = 0.0009899999999998244\nfound new max: 0.0010479999999999379  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'acousticness'] \niteration= 5, accuarcy = 0.0010479999999999379\nfound new max: 0.0010620000000001184  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'speechiness'] \niteration= 5, accuarcy = 0.0010620000000001184\nfound new max: 0.0011009999999993525  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'popularity'] \niteration= 5, accuarcy = 0.0011009999999993525\nfound new max: 0.0009860000000001534  optimal features = ['beat', 'energy', 'danceability', 'valence', 'duration'] \niteration= 5, accuarcy = 0.0009860000000001534\nfound new max: 0.00093600000000027  optimal features = ['beat', 'energy', 'danceability', 'valence', 'acousticness'] \niteration= 5, accuarcy = 0.00093600000000027\nfound new max: 0.0009959999999997748  optimal features = ['beat', 'energy', 'danceability', 'valence', 'speechiness'] \niteration= 5, accuarcy = 0.0009959999999997748\nfound new max: 0.00093600000000027  optimal features = ['beat', 'energy', 'danceability', 'valence', 'popularity'] \niteration= 5, accuarcy = 0.00093600000000027\nfound new max: 0.0010529999999997486  optimal features = ['beat', 'energy', 'danceability', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0010529999999997486\nfound new max: 0.0008869999999996381  optimal features = ['beat', 'energy', 'danceability', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.0008869999999996381\nfound new max: 0.0008630000000007243  optimal features = ['beat', 'energy', 'danceability', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.0008630000000007243\nfound new max: 0.0010950000000002902  optimal features = ['beat', 'energy', 'danceability', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0010950000000002902\nfound new max: 0.0009079999999999089  optimal features = ['beat', 'energy', 'danceability', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0009079999999999089\nfound new max: 0.0014249999999993435  optimal features = ['beat', 'energy', 'danceability', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0014249999999993435\nfound new max: 0.0009339999999999904  optimal features = ['beat', 'energy', 'loudness', 'valence', 'duration'] \niteration= 5, accuarcy = 0.0009339999999999904\nfound new max: 0.0010500000000002174  optimal features = ['beat', 'energy', 'loudness', 'valence', 'acousticness'] \niteration= 5, accuarcy = 0.0010500000000002174\nfound new max: 0.0009129999999997196  optimal features = ['beat', 'energy', 'loudness', 'valence', 'speechiness'] \niteration= 5, accuarcy = 0.0009129999999997196\nfound new max: 0.0008739999999995973  optimal features = ['beat', 'energy', 'loudness', 'valence', 'popularity'] \niteration= 5, accuarcy = 0.0008739999999995973\nfound new max: 0.0008930000000004767  optimal features = ['beat', 'energy', 'loudness', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0008930000000004767\nfound new max: 0.0012609999999995125  optimal features = ['beat', 'energy', 'loudness', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.0012609999999995125\nfound new max: 0.001274999999999693  optimal features = ['beat', 'energy', 'loudness', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.001274999999999693\nfound new max: 0.0009410000000000807  optimal features = ['beat', 'energy', 'loudness', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0009410000000000807\nfound new max: 0.0013810000000002987  optimal features = ['beat', 'energy', 'loudness', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0013810000000002987\nfound new max: 0.0009219999999992012  optimal features = ['beat', 'energy', 'loudness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009219999999992012\nfound new max: 0.0008840000000001069  optimal features = ['beat', 'energy', 'valence', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0008840000000001069\nfound new max: 0.0011120000000000019  optimal features = ['beat', 'energy', 'valence', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.0011120000000000019\nfound new max: 0.0009060000000005175  optimal features = ['beat', 'energy', 'valence', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.0009060000000005175\nfound new max: 0.0012979999999993552  optimal features = ['beat', 'energy', 'valence', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0012979999999993552\nfound new max: 0.0009209999999999496  optimal features = ['beat', 'energy', 'valence', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0009209999999999496\nfound new max: 0.0008729999999994575  optimal features = ['beat', 'energy', 'valence', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0008729999999994575\nfound new max: 0.0009830000000006223  optimal features = ['beat', 'energy', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0009830000000006223\nfound new max: 0.001108000000000331  optimal features = ['beat', 'energy', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.001108000000000331\nfound new max: 0.0013130000000005637  optimal features = ['beat', 'energy', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0013130000000005637\nfound new max: 0.0009350000000001302  optimal features = ['beat', 'energy', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009350000000001302\nfound new max: 0.0011120000000000019  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'duration'] \niteration= 5, accuarcy = 0.0011120000000000019\nfound new max: 0.0009270000000007883  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'acousticness'] \niteration= 5, accuarcy = 0.0009270000000007883\nfound new max: 0.0009009999999998186  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'speechiness'] \niteration= 5, accuarcy = 0.0009009999999998186\nfound new max: 0.0009980000000000544  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'popularity'] \niteration= 5, accuarcy = 0.0009980000000000544\nfound new max: 0.0010050000000001447  optimal features = ['beat', 'danceability', 'loudness', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0010050000000001447\nfound new max: 0.000900000000000567  optimal features = ['beat', 'danceability', 'loudness', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.000900000000000567\nfound new max: 0.0010310000000002262  optimal features = ['beat', 'danceability', 'loudness', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.0010310000000002262\nfound new max: 0.0008720000000002059  optimal features = ['beat', 'danceability', 'loudness', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0008720000000002059\nfound new max: 0.0009909999999999641  optimal features = ['beat', 'danceability', 'loudness', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0009909999999999641\nfound new max: 0.0009870000000002932  optimal features = ['beat', 'danceability', 'loudness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009870000000002932\nfound new max: 0.0010810000000001097  optimal features = ['beat', 'danceability', 'valence', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0010810000000001097\nfound new max: 0.0009559999999995128  optimal features = ['beat', 'danceability', 'valence', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.0009559999999995128\nfound new max: 0.0010090000000007038  optimal features = ['beat', 'danceability', 'valence', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.0010090000000007038\nfound new max: 0.001014999999999766  optimal features = ['beat', 'danceability', 'valence', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.001014999999999766\nfound new max: 0.0013350000000000861  optimal features = ['beat', 'danceability', 'valence', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0013350000000000861\nfound new max: 0.001068000000000069  optimal features = ['beat', 'danceability', 'valence', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.001068000000000069\nfound new max: 0.001600000000000712  optimal features = ['beat', 'danceability', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.001600000000000712\nfound new max: 0.0015399999999994307  optimal features = ['beat', 'danceability', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0015399999999994307\nfound new max: 0.0009280000000000399  optimal features = ['beat', 'danceability', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009280000000000399\nfound new max: 0.001044000000000267  optimal features = ['beat', 'danceability', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.001044000000000267\nfound new max: 0.0012670000000003512  optimal features = ['beat', 'loudness', 'valence', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0012670000000003512\nfound new max: 0.0011030000000005202  optimal features = ['beat', 'loudness', 'valence', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.0011030000000005202\nfound new max: 0.0010870000000000601  optimal features = ['beat', 'loudness', 'valence', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.0010870000000000601\nfound new max: 0.0009350000000001302  optimal features = ['beat', 'loudness', 'valence', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0009350000000001302\nfound new max: 0.0010040000000000049  optimal features = ['beat', 'loudness', 'valence', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0010040000000000049\nfound new max: 0.0008770000000000167  optimal features = ['beat', 'loudness', 'valence', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0008770000000000167\nfound new max: 0.0009430000000003602  optimal features = ['beat', 'loudness', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0009430000000003602\nfound new max: 0.0008879999999997779  optimal features = ['beat', 'loudness', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0008879999999997779\nfound new max: 0.0008939999999997283  optimal features = ['beat', 'loudness', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0008939999999997283\nfound new max: 0.0012569999999998416  optimal features = ['beat', 'loudness', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0012569999999998416\nfound new max: 0.0009079999999999089  optimal features = ['beat', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0009079999999999089\nfound new max: 0.0009319999999997108  optimal features = ['beat', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0009319999999997108\nfound new max: 0.001064000000000398  optimal features = ['beat', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.001064000000000398\nfound new max: 0.000968000000000302  optimal features = ['beat', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.000968000000000302\nfound new max: 0.000900000000000567  optimal features = ['beat', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.000900000000000567\nfound new max: 0.0010349999999998971  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'duration'] \niteration= 5, accuarcy = 0.0010349999999998971\nfound new max: 0.0009510000000005903  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'acousticness'] \niteration= 5, accuarcy = 0.0009510000000005903\nfound new max: 0.0009509999999997021  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'speechiness'] \niteration= 5, accuarcy = 0.0009509999999997021\nfound new max: 0.0012059999999998183  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'popularity'] \niteration= 5, accuarcy = 0.0012059999999998183\nfound new max: 0.0009230000000002292  optimal features = ['energy', 'danceability', 'loudness', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0009230000000002292\nfound new max: 0.0010229999999999961  optimal features = ['energy', 'danceability', 'loudness', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.0010229999999999961\nfound new max: 0.001152000000000264  optimal features = ['energy', 'danceability', 'loudness', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.001152000000000264\nfound new max: 0.0009230000000002292  optimal features = ['energy', 'danceability', 'loudness', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0009230000000002292\nfound new max: 0.0009540000000001214  optimal features = ['energy', 'danceability', 'loudness', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0009540000000001214\nfound new max: 0.0011070000000001912  optimal features = ['energy', 'danceability', 'loudness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0011070000000001912\nfound new max: 0.0009239999999994808  optimal features = ['energy', 'danceability', 'valence', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0009239999999994808\nfound new max: 0.0010300000000000864  optimal features = ['energy', 'danceability', 'valence', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.0010300000000000864\nfound new max: 0.0011490000000007328  optimal features = ['energy', 'danceability', 'valence', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.0011490000000007328\nfound new max: 0.0012930000000004327  optimal features = ['energy', 'danceability', 'valence', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0012930000000004327\nfound new max: 0.0010110000000000952  optimal features = ['energy', 'danceability', 'valence', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0010110000000000952\nfound new max: 0.0010610000000008668  optimal features = ['energy', 'danceability', 'valence', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0010610000000008668\nfound new max: 0.000934999999999242  optimal features = ['energy', 'danceability', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.000934999999999242\nfound new max: 0.0009189999999996701  optimal features = ['energy', 'danceability', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0009189999999996701\nfound new max: 0.0010300000000000864  optimal features = ['energy', 'danceability', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0010300000000000864\nfound new max: 0.000892000000000337  optimal features = ['energy', 'danceability', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.000892000000000337\nfound new max: 0.0008879999999997779  optimal features = ['energy', 'loudness', 'valence', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0008879999999997779\nfound new max: 0.0010050000000001447  optimal features = ['energy', 'loudness', 'valence', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.0010050000000001447\nfound new max: 0.0009139999999998594  optimal features = ['energy', 'loudness', 'valence', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.0009139999999998594\nfound new max: 0.0008879999999997779  optimal features = ['energy', 'loudness', 'valence', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0008879999999997779\nfound new max: 0.0009110000000003282  optimal features = ['energy', 'loudness', 'valence', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0009110000000003282\nfound new max: 0.0009179999999995303  optimal features = ['energy', 'loudness', 'valence', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009179999999995303\nfound new max: 0.0008660000000002555  optimal features = ['energy', 'loudness', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0008660000000002555\nfound new max: 0.0010620000000001184  optimal features = ['energy', 'loudness', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0010620000000001184\nfound new max: 0.0008780000000001564  optimal features = ['energy', 'loudness', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0008780000000001564\nfound new max: 0.0008759999999998769  optimal features = ['energy', 'loudness', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0008759999999998769\nfound new max: 0.001076000000000299  optimal features = ['energy', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.001076000000000299\nfound new max: 0.0010569999999994195  optimal features = ['energy', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0010569999999994195\nfound new max: 0.0009030000000000982  optimal features = ['energy', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009030000000000982\nfound new max: 0.0009169999999993905  optimal features = ['energy', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009169999999993905\nfound new max: 0.0009569999999996526  optimal features = ['energy', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009569999999996526\nfound new max: 0.0009489999999994225  optimal features = ['danceability', 'loudness', 'valence', 'duration', 'acousticness'] \niteration= 5, accuarcy = 0.0009489999999994225\nfound new max: 0.0009959999999997748  optimal features = ['danceability', 'loudness', 'valence', 'duration', 'speechiness'] \niteration= 5, accuarcy = 0.0009959999999997748\nfound new max: 0.0009930000000002437  optimal features = ['danceability', 'loudness', 'valence', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.0009930000000002437\nfound new max: 0.0009620000000003515  optimal features = ['danceability', 'loudness', 'valence', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0009620000000003515\nfound new max: 0.001046999999999798  optimal features = ['danceability', 'loudness', 'valence', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.001046999999999798\nfound new max: 0.0010750000000001592  optimal features = ['danceability', 'loudness', 'valence', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0010750000000001592\nfound new max: 0.0009039999999993498  optimal features = ['danceability', 'loudness', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0009039999999993498\nfound new max: 0.0014619999999991862  optimal features = ['danceability', 'loudness', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0014619999999991862\nfound new max: 0.0012639999999999318  optimal features = ['danceability', 'loudness', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0012639999999999318\nfound new max: 0.00093600000000027  optimal features = ['danceability', 'loudness', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.00093600000000027\nfound new max: 0.0009850000000000136  optimal features = ['danceability', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0009850000000000136\nfound new max: 0.0009030000000000982  optimal features = ['danceability', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0009030000000000982\nfound new max: 0.0011770000000002057  optimal features = ['danceability', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0011770000000002057\nfound new max: 0.0010859999999999204  optimal features = ['danceability', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0010859999999999204\nfound new max: 0.0013569999999996085  optimal features = ['danceability', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0013569999999996085\nfound new max: 0.0012020000000001474  optimal features = ['loudness', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 5, accuarcy = 0.0012020000000001474\nfound new max: 0.0009980000000000544  optimal features = ['loudness', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 5, accuarcy = 0.0009980000000000544\nfound new max: 0.0011060000000000514  optimal features = ['loudness', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0011060000000000514\nfound new max: 0.0009930000000002437  optimal features = ['loudness', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009930000000002437\nfound new max: 0.0011499999999999844  optimal features = ['loudness', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0011499999999999844\nfound new max: 0.0009230000000002292  optimal features = ['valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 5, accuarcy = 0.0009230000000002292\nfound new max: 0.0011999999999998678  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'duration'] \niteration= 6, accuarcy = 0.0011999999999998678\nfound new max: 0.0013980000000000103  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'acousticness'] \niteration= 6, accuarcy = 0.0013980000000000103\nfound new max: 0.000988000000000433  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'speechiness'] \niteration= 6, accuarcy = 0.000988000000000433\nfound new max: 0.001026999999999667  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'popularity'] \niteration= 6, accuarcy = 0.001026999999999667\nfound new max: 0.0009110000000003282  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'duration', 'acousticness'] \niteration= 6, accuarcy = 0.0009110000000003282\nfound new max: 0.0010989999999999611  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'duration', 'speechiness'] \niteration= 6, accuarcy = 0.0010989999999999611\nfound new max: 0.0009090000000000487  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'duration', 'popularity'] \niteration= 6, accuarcy = 0.0009090000000000487\nfound new max: 0.0013730000000000686  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0013730000000000686\nfound new max: 0.001032000000000366  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.001032000000000366\nfound new max: 0.001094999999999402  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.001094999999999402\nfound new max: 0.0013740000000002084  optimal features = ['beat', 'energy', 'danceability', 'valence', 'duration', 'acousticness'] \niteration= 6, accuarcy = 0.0013740000000002084\nfound new max: 0.0012199999999999989  optimal features = ['beat', 'energy', 'danceability', 'valence', 'duration', 'speechiness'] \niteration= 6, accuarcy = 0.0012199999999999989\nfound new max: 0.0011369999999999436  optimal features = ['beat', 'energy', 'danceability', 'valence', 'duration', 'popularity'] \niteration= 6, accuarcy = 0.0011369999999999436\nfound new max: 0.0011740000000006745  optimal features = ['beat', 'energy', 'danceability', 'valence', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0011740000000006745\nfound new max: 0.0009619999999994633  optimal features = ['beat', 'energy', 'danceability', 'valence', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0009619999999994633\nfound new max: 0.00107899999999983  optimal features = ['beat', 'energy', 'danceability', 'valence', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.00107899999999983\nfound new max: 0.0010979999999998213  optimal features = ['beat', 'energy', 'danceability', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0010979999999998213\nfound new max: 0.0009420000000002204  optimal features = ['beat', 'energy', 'danceability', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0009420000000002204\nfound new max: 0.0013019999999999143  optimal features = ['beat', 'energy', 'danceability', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0013019999999999143\nfound new max: 0.0010470000000006863  optimal features = ['beat', 'energy', 'danceability', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0010470000000006863\nfound new max: 0.0009690000000004417  optimal features = ['beat', 'energy', 'loudness', 'valence', 'duration', 'acousticness'] \niteration= 6, accuarcy = 0.0009690000000004417\nfound new max: 0.0009959999999997748  optimal features = ['beat', 'energy', 'loudness', 'valence', 'duration', 'speechiness'] \niteration= 6, accuarcy = 0.0009959999999997748\nfound new max: 0.0008840000000001069  optimal features = ['beat', 'energy', 'loudness', 'valence', 'duration', 'popularity'] \niteration= 6, accuarcy = 0.0008840000000001069\nfound new max: 0.0009090000000000487  optimal features = ['beat', 'energy', 'loudness', 'valence', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0009090000000000487\nfound new max: 0.0013130000000005637  optimal features = ['beat', 'energy', 'loudness', 'valence', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0013130000000005637\nfound new max: 0.0009339999999999904  optimal features = ['beat', 'energy', 'loudness', 'valence', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009339999999999904\nfound new max: 0.0008819999999998274  optimal features = ['beat', 'energy', 'loudness', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0008819999999998274\nfound new max: 0.0013689999999995095  optimal features = ['beat', 'energy', 'loudness', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0013689999999995095\nfound new max: 0.0009459999999998914  optimal features = ['beat', 'energy', 'loudness', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009459999999998914\nfound new max: 0.0008900000000000574  optimal features = ['beat', 'energy', 'loudness', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0008900000000000574\nfound new max: 0.0009610000000002117  optimal features = ['beat', 'energy', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0009610000000002117\nfound new max: 0.0008930000000004767  optimal features = ['beat', 'energy', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0008930000000004767\nfound new max: 0.0008750000000006253  optimal features = ['beat', 'energy', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0008750000000006253\nfound new max: 0.0008819999999998274  optimal features = ['beat', 'energy', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0008819999999998274\nfound new max: 0.0010669999999999291  optimal features = ['beat', 'energy', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0010669999999999291\nfound new max: 0.0009369999999995215  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'duration', 'acousticness'] \niteration= 6, accuarcy = 0.0009369999999995215\nfound new max: 0.0009049999999994895  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'duration', 'speechiness'] \niteration= 6, accuarcy = 0.0009049999999994895\nfound new max: 0.0009280000000000399  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'duration', 'popularity'] \niteration= 6, accuarcy = 0.0009280000000000399\nfound new max: 0.0009249999999996206  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0009249999999996206\nfound new max: 0.000904000000000238  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.000904000000000238\nfound new max: 0.0009129999999997196  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009129999999997196\nfound new max: 0.0009830000000006223  optimal features = ['beat', 'danceability', 'loudness', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0009830000000006223\nfound new max: 0.0008829999999999671  optimal features = ['beat', 'danceability', 'loudness', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0008829999999999671\nfound new max: 0.0008660000000002555  optimal features = ['beat', 'danceability', 'loudness', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0008660000000002555\nfound new max: 0.0013670000000001181  optimal features = ['beat', 'danceability', 'loudness', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0013670000000001181\nfound new max: 0.0010969999999996816  optimal features = ['beat', 'danceability', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0010969999999996816\nfound new max: 0.0009300000000003195  optimal features = ['beat', 'danceability', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0009300000000003195\nfound new max: 0.0008940000000006165  optimal features = ['beat', 'danceability', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0008940000000006165\nfound new max: 0.0009679999999994138  optimal features = ['beat', 'danceability', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009679999999994138\nfound new max: 0.0010740000000000194  optimal features = ['beat', 'danceability', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0010740000000000194\nfound new max: 0.0009629999999996031  optimal features = ['beat', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0009629999999996031\nfound new max: 0.0009890000000005728  optimal features = ['beat', 'loudness', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0009890000000005728\nfound new max: 0.0009039999999993498  optimal features = ['beat', 'loudness', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009039999999993498\nfound new max: 0.0008819999999998274  optimal features = ['beat', 'loudness', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0008819999999998274\nfound new max: 0.0009060000000005175  optimal features = ['beat', 'loudness', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009060000000005175\nfound new max: 0.0008749999999997371  optimal features = ['beat', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0008749999999997371\nfound new max: 0.0008970000000001477  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'duration', 'acousticness'] \niteration= 6, accuarcy = 0.0008970000000001477\nfound new max: 0.001038999999999568  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'duration', 'speechiness'] \niteration= 6, accuarcy = 0.001038999999999568\nfound new max: 0.0009730000000001127  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'duration', 'popularity'] \niteration= 6, accuarcy = 0.0009730000000001127\nfound new max: 0.0008829999999999671  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0008829999999999671\nfound new max: 0.0009030000000000982  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0009030000000000982\nfound new max: 0.001010999999999207  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.001010999999999207\nfound new max: 0.000892000000000337  optimal features = ['energy', 'danceability', 'loudness', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.000892000000000337\nfound new max: 0.0009660000000000224  optimal features = ['energy', 'danceability', 'loudness', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0009660000000000224\nfound new max: 0.0010799999999999699  optimal features = ['energy', 'danceability', 'loudness', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0010799999999999699\nfound new max: 0.0009139999999998594  optimal features = ['energy', 'danceability', 'loudness', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009139999999998594\nfound new max: 0.0008899999999991692  optimal features = ['energy', 'danceability', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0008899999999991692\nfound new max: 0.001048000000000826  optimal features = ['energy', 'danceability', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.001048000000000826\nfound new max: 0.0009540000000001214  optimal features = ['energy', 'danceability', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009540000000001214\nfound new max: 0.0009440000000005  optimal features = ['energy', 'danceability', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009440000000005\nfound new max: 0.00091099999999944  optimal features = ['energy', 'danceability', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.00091099999999944\nfound new max: 0.000878999999999408  optimal features = ['energy', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.000878999999999408\nfound new max: 0.0009579999999997924  optimal features = ['energy', 'loudness', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0009579999999997924\nfound new max: 0.0009329999999998506  optimal features = ['energy', 'loudness', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009329999999998506\nfound new max: 0.0009370000000004097  optimal features = ['energy', 'loudness', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009370000000004097\nfound new max: 0.0009889999999996846  optimal features = ['energy', 'loudness', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009889999999996846\nfound new max: 0.0008749999999997371  optimal features = ['energy', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0008749999999997371\nfound new max: 0.0009969999999999146  optimal features = ['danceability', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 6, accuarcy = 0.0009969999999999146\nfound new max: 0.0009239999999994808  optimal features = ['danceability', 'loudness', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 6, accuarcy = 0.0009239999999994808\nfound new max: 0.0009439999999996118  optimal features = ['danceability', 'loudness', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009439999999996118\nfound new max: 0.0011369999999999436  optimal features = ['danceability', 'loudness', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0011369999999999436\nfound new max: 0.0009509999999997021  optimal features = ['danceability', 'loudness', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009509999999997021\nfound new max: 0.0009889999999996846  optimal features = ['danceability', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0009889999999996846\nfound new max: 0.0010249999999993875  optimal features = ['loudness', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 6, accuarcy = 0.0010249999999993875\nfound new max: 0.0009159999999992507  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'duration', 'acousticness'] \niteration= 7, accuarcy = 0.0009159999999992507\nfound new max: 0.0012100000000003774  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'duration', 'speechiness'] \niteration= 7, accuarcy = 0.0012100000000003774\nfound new max: 0.0009579999999997924  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'duration', 'popularity'] \niteration= 7, accuarcy = 0.0009579999999997924\nfound new max: 0.0012409999999993815  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'acousticness', 'speechiness'] \niteration= 7, accuarcy = 0.0012409999999993815\nfound new max: 0.0010989999999999611  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'acousticness', 'popularity'] \niteration= 7, accuarcy = 0.0010989999999999611\nfound new max: 0.0014070000000003802  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0014070000000003802\nfound new max: 0.0011499999999999844  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'duration', 'acousticness', 'speechiness'] \niteration= 7, accuarcy = 0.0011499999999999844\nfound new max: 0.0011539999999996553  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'duration', 'acousticness', 'popularity'] \niteration= 7, accuarcy = 0.0011539999999996553\nfound new max: 0.0009380000000005495  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'duration', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0009380000000005495\nfound new max: 0.0012559999999997018  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0012559999999997018\nfound new max: 0.0010650000000005377  optimal features = ['beat', 'energy', 'danceability', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 7, accuarcy = 0.0010650000000005377\nfound new max: 0.000992000000000104  optimal features = ['beat', 'energy', 'danceability', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 7, accuarcy = 0.000992000000000104\nfound new max: 0.001158999999999466  optimal features = ['beat', 'energy', 'danceability', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.001158999999999466\nfound new max: 0.0010519999999996088  optimal features = ['beat', 'energy', 'danceability', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0010519999999996088\nfound new max: 0.0009269999999999001  optimal features = ['beat', 'energy', 'danceability', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0009269999999999001\nfound new max: 0.0009420000000002204  optimal features = ['beat', 'energy', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 7, accuarcy = 0.0009420000000002204\nfound new max: 0.0010830000000003892  optimal features = ['beat', 'energy', 'loudness', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 7, accuarcy = 0.0010830000000003892\nfound new max: 0.0009500000000004505  optimal features = ['beat', 'energy', 'loudness', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0009500000000004505\nfound new max: 0.0009059999999996293  optimal features = ['beat', 'energy', 'loudness', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0009059999999996293\nfound new max: 0.0010989999999999611  optimal features = ['beat', 'energy', 'loudness', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0010989999999999611\nfound new max: 0.0015779999999994132  optimal features = ['beat', 'energy', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0015779999999994132\nfound new max: 0.0010040000000000049  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 7, accuarcy = 0.0010040000000000049\nfound new max: 0.0009079999999999089  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 7, accuarcy = 0.0009079999999999089\nfound new max: 0.0008949999999998681  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0008949999999998681\nfound new max: 0.0010079999999996758  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0010079999999996758\nfound new max: 0.0009759999999996438  optimal features = ['beat', 'danceability', 'loudness', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0009759999999996438\nfound new max: 0.0010880000000002  optimal features = ['beat', 'danceability', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0010880000000002\nfound new max: 0.0009230000000002292  optimal features = ['beat', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0009230000000002292\nfound new max: 0.0009149999999999991  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 7, accuarcy = 0.0009149999999999991\nfound new max: 0.000904000000000238  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 7, accuarcy = 0.000904000000000238\nfound new max: 0.000992000000000104  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.000992000000000104\nfound new max: 0.0010930000000000106  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0010930000000000106\nfound new max: 0.000924000000000369  optimal features = ['energy', 'danceability', 'loudness', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.000924000000000369\nfound new max: 0.0008989999999995391  optimal features = ['energy', 'danceability', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0008989999999995391\nfound new max: 0.0011190000000000921  optimal features = ['energy', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0011190000000000921\nfound new max: 0.0009979999999991662  optimal features = ['danceability', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 7, accuarcy = 0.0009979999999991662\nfound new max: 0.000998999999999306  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness'] \niteration= 8, accuarcy = 0.000998999999999306\nfound new max: 0.0009410000000000807  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'duration', 'acousticness', 'popularity'] \niteration= 8, accuarcy = 0.0009410000000000807\nfound new max: 0.0009730000000001127  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'duration', 'speechiness', 'popularity'] \niteration= 8, accuarcy = 0.0009730000000001127\nfound new max: 0.0009019999999999584  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'acousticness', 'speechiness', 'popularity'] \niteration= 8, accuarcy = 0.0009019999999999584\nfound new max: 0.0008780000000001564  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 8, accuarcy = 0.0008780000000001564\nfound new max: 0.0013980000000000103  optimal features = ['beat', 'energy', 'danceability', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 8, accuarcy = 0.0013980000000000103\nfound new max: 0.0009220000000000894  optimal features = ['beat', 'energy', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 8, accuarcy = 0.0009220000000000894\nfound new max: 0.0010360000000000369  optimal features = ['beat', 'danceability', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 8, accuarcy = 0.0010360000000000369\nfound new max: 0.000982999999999734  optimal features = ['energy', 'danceability', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 8, accuarcy = 0.000982999999999734\nfound new max: 0.0009170000000002787  optimal features = ['beat', 'energy', 'danceability', 'loudness', 'valence', 'duration', 'acousticness', 'speechiness', 'popularity'] \niteration= 9, accuarcy = 0.0009170000000002787\n\n\n\nacc\n\n0.0009170000000002787\n\n\n\nsubset\n\n['beat',\n 'energy',\n 'danceability',\n 'loudness',\n 'valence',\n 'duration',\n 'acousticness',\n 'speechiness',\n 'popularity']"
  },
  {
    "objectID": "naive_bayes_record.html#final-result",
    "href": "naive_bayes_record.html#final-result",
    "title": "Naive Bayes on Record Data",
    "section": "Final Result",
    "text": "Final Result\n\ndef generate_final_result(x_train, y_train, x_test, y_test):\n\n    gnb = GaussianNB()\n    gnb.fit(x_train, y_train)\n    y_pred = gnb.predict(x_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    accuracy_train = accuracy_score(y_train, gnb.predict(x_train))\n    f1 = f1_score(y_test, y_pred, pos_label='2010-2014')\n\n    \n    return f1, accuracy, accuracy_train, y_pred, y_test\n\n\nf1, accuarcy, accuracy_train, y_pred, y_test = generate_final_result(x_train[subset], y_train, x_test[subset], y_test)\n\n\nf1\n\n0.7665198237885462\n\n\n\naccuarcy\n\n0.7071823204419889\n\n\n\nconf_matrix = metrics.confusion_matrix(y_test, y_pred, labels=['2010-2014', '2015-2019'])\n\nplt.title(\"Confusion matrix\")\naxis = sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\naxis.set_xticklabels(['2010-2014', '2015-2019'])\naxis.set_yticklabels(['2010-2014', '2015-2019'])\naxis.set(xlabel=\"Predicted\", ylabel=\"True\")\nplt.show()\n\n\n\n\nAccording to the confusion matrix, this model would violently biased to the case of 2010-2014. This could be a result of the lack of data in general. Though the accuracy is not bad but the model is not very useful in practice because of the high bias."
  },
  {
    "objectID": "naive_bayes_record.html#discussion",
    "href": "naive_bayes_record.html#discussion",
    "title": "Naive Bayes on Record Data",
    "section": "Discussion",
    "text": "Discussion\n\nThe modle was trained using the sklern inbulit GaussianNB function. Using the fit method to train on the training dataset and predict method to test on the test set.\nThe model has a good accuarcy but a terrible recall for class 2010-2014. So although the model can predict the year of the song. The F1 score for class 2010-2014 is decent but for another class is not pretty satisfying.This could be the result of the lack of data in general.\nOverfitting is when the model is too complex to learn even the noise of the training data, while underfitting is when the model is too simple and fail to learn the pattern at all. While overfitting has a high variance and low bias while overfitting could have low variance and high bias. In this case, due to the high bias, the model is more likely to be underfitting.\nThe project finds that there is a possible way to use the acoustic features of a song to roughly decide its year of release. If there is a need for a report, this should be documented using like a R markdown or Jupyter notebook so the result is reproduceable. What should be reported include how the modle was trained, what is the dataset, the result and the limitation."
  },
  {
    "objectID": "naive_bayes_record.html#feature-selection-for-record-data-using-variance-threshold",
    "href": "naive_bayes_record.html#feature-selection-for-record-data-using-variance-threshold",
    "title": "Naive Bayes on Record Data",
    "section": "Feature Selection for record data (Using Variance Threshold)",
    "text": "Feature Selection for record data (Using Variance Threshold)\n\n# VARIANCE THRESHOLD SEARCH\n\nfrom sklearn.feature_selection import VarianceThreshold\n\nx_var=np.var(X,axis=0)\n# DEFINE GRID OF THRESHOLDS \nnum_thresholds=10\nthresholds=np.linspace(np.min(x_var),np.max(x_var),num_thresholds)\n\n# DOESN\"T WORK WELL WITH EDGE VALUES (ZERO VAR)\nthresholds=thresholds[1:-2]; #print(thresholds)\n\n# INITIALIZE ARRAYS\nnum_features=[]\ntrain_accuracies=[]\ntest_accuracies=[]\ntrain_time = []\neval_time = []\n\n#FULL TRAINING SET\n\n(acc_train,acc_test, time_train, time_eval)=train_and_test(X_train,y_train,X_test,y_test,i_print=True)\nnum_features.append(X.shape[1])\ntrain_accuracies.append(acc_train)\ntest_accuracies.append(acc_test)\ntrain_time.append(time_train)\neval_time.append(time_eval)\n\n# SEARCH FOR OPTIMAL THRESHOLD\nfor THRESHOLD in thresholds:\n    feature_selector = VarianceThreshold(threshold=THRESHOLD)\n    xtmp=feature_selector.fit_transform(X)\n    print(THRESHOLD, xtmp.shape[1])\n\n    x_train=xtmp[train_index]; y_train=y[train_index]\n    x_test=xtmp[test_index]; y_test=y[test_index]\n\n\n    (acc_train,acc_test, time_train, time_eval)=train_and_test(x_train,y_train,x_test,y_test,i_print=False)\n             \n    #RECORD \n    num_features.append(xtmp.shape[1])\n    train_accuracies.append(acc_train)\n    test_accuracies.append(acc_test)\n    train_time.append(time_train)\n    eval_time.append(time_eval)\n\n\n59.50413223140496 65.56016597510373\n136.16184967918835 7\n264.507765209332 5\n392.8536807394756 4\n521.1995962696192 2\n649.5455117997628 1\n777.8914273299064 1\n906.23734286005 1\n\n\n\neval_time\n\n[0.0005700000000032901,\n 0.00014000000000180535,\n 0.00015100000000245473,\n 0.00010799999999733245,\n 0.00011200000000144428,\n 9.800000000126374e-05,\n 0.00010000000000331966,\n 9.299999999967667e-05]\n\n\n\nnum_features\n\n[9, 7, 5, 4, 2, 1, 1, 1]\n\n\n\n#UTILITY FUNCTION TO PLOT RESULTS\ndef plot_results():\n\n    #PLOT-1\n    plt.plot(num_features,train_accuracies,'-or')\n    plt.plot(num_features,test_accuracies,'-ob')\n    plt.xlabel('Number of features')\n    plt.ylabel('ACCURACY: Training (red) and Test (blue)')\n    plt.show()\n\n    # #PLOT-2\n    plt.plot(num_features,train_time,'-or')\n    plt.plot(num_features,eval_time,'-ob')\n    plt.xlabel('Number of features')\n    plt.ylabel('Runtime: training time (red) and evaluation time(blue)')\n    plt.show()\n\n    # #PLOT-3\n    plt.plot(num_features,np.array(train_accuracies)-np.array(test_accuracies),'-or')\n    plt.xlabel('Number of features')\n    plt.ylabel('train_accuracies-test_accuracies')\n    plt.show()\n\n\nmax(test_accuracies)\n\n0.6574585635359116\n\n\n\nplot_results()\n\n\n\n\n\n\n\n\n\n\n\nThe first graph shows the performance of the model’s trend during the added features. Both the training and testing accuarcy were at peak when the feature number is 9 (all of them), which should be the best number of features to use. The best accuarcy it can give is about 0.68. The interesting thing is that the accuarcy of training are lower than the testing accuarcy. It could be a result of underfitting due to the lack of features or simple nature of naive bayes.\nThis graph shows the time used for training and testing related to the number of the features. It can be observed that after the feature number is greater than 7 the time consumption for training and testing increased dramatically. Therefore, 7 is the best number for reducing time cost.\nThis graph shown how the difference of the accuarcy between the training and testing change according to the number of features. It can be observed that the difference is quite low when the feature number is 7 and and 1."
  },
  {
    "objectID": "naive_bayes_record.html#feature-selection-for-record-data-using-iterative-feature-selection",
    "href": "naive_bayes_record.html#feature-selection-for-record-data-using-iterative-feature-selection",
    "title": "Naive Bayes on Record Data",
    "section": "Feature Selection for record data (Using iterative feature selection)",
    "text": "Feature Selection for record data (Using iterative feature selection)\n\nimport itertools\n\n\ndef maximize_CFS(x,y):\n     \n     df_x = x\n     column_names = df_x.columns\n\n     N=X.shape[0]\n     l = [*range(N)]       # indices\n     cut = int(0.7 * N)    # 80% of the list\n     random.shuffle(l)     # randomize\n     train_index = l[:cut] # first 80% of shuffled list\n     test_index = l[cut:]  # last 20% of shuffled list\n\n     max_accuracy = 0\n     y_train=y[train_index]\n     y_test=y[test_index]\n     \n     for L in range(1,len(column_names) + 1):\n          for subset in itertools.combinations(column_names, L):\n               # print(df_x[list(subset)].values.shape)\n               temp = df_x[list(subset)]\n               x_train=temp.iloc[train_index]\n               x_test=temp.iloc[test_index]\n               _, accuracy, _, _ = train_and_test(x_train, y_train, x_test, y_test)\n               if accuracy &gt; max_accuracy:\n                    max_accuracy = accuracy\n                    max_subset = list(subset)\n                    print(f'found new max: {max_accuracy}  optimal features = {max_subset} \\niteration= {L}, accuarcy = {accuracy}')\n          \n     \n     return max_accuracy, max_subset, y_test, x_test, y_train, x_train\n\n\nacc, subset, y_test, x_test, y_train, x_train = maximize_CFS(X,y)\n\nfound new max: 0.585635359116022  optimal features = ['beat'] \niteration= 1, accuarcy = 0.585635359116022\nfound new max: 0.5966850828729282  optimal features = ['danceability'] \niteration= 1, accuarcy = 0.5966850828729282\nfound new max: 0.6408839779005525  optimal features = ['popularity'] \niteration= 1, accuarcy = 0.6408839779005525\nfound new max: 0.6519337016574586  optimal features = ['duration', 'popularity'] \niteration= 2, accuarcy = 0.6519337016574586\nfound new max: 0.6574585635359116  optimal features = ['beat', 'duration', 'popularity'] \niteration= 3, accuarcy = 0.6574585635359116\nfound new max: 0.6629834254143646  optimal features = ['energy', 'duration', 'popularity'] \niteration= 3, accuarcy = 0.6629834254143646\nfound new max: 0.6685082872928176  optimal features = ['beat', 'danceability', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.6685082872928176\nfound new max: 0.6740331491712708  optimal features = ['beat', 'valence', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.6740331491712708\nfound new max: 0.6961325966850829  optimal features = ['danceability', 'valence', 'duration', 'popularity'] \niteration= 4, accuarcy = 0.6961325966850829\nfound new max: 0.7071823204419889  optimal features = ['beat', 'danceability', 'valence', 'duration', 'popularity'] \niteration= 5, accuarcy = 0.7071823204419889\n\n\n\nacc\n\n0.7071823204419889\n\n\n\nsubset\n\n['beat', 'danceability', 'valence', 'duration', 'popularity']\n\n\nUsing the iterative feature selection, the best features combination were selected and the accuarcy is higher than using the variance threshold in the last case. So I will use this as the final result."
  }
]